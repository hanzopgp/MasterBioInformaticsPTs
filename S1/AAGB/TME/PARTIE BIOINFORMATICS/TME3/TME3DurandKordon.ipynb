{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karna\\anaconda3\\lib\\site-packages\\ete3-3.1.2-py3.7.egg\\ete3\\evol\\parser\\codemlparser.py:221: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\karna\\anaconda3\\lib\\site-packages\\ete3-3.1.2-py3.7.egg\\ete3\\evol\\parser\\codemlparser.py:221: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ete3 import Tree\n",
    "import pprint\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_MATRIX = np.array([[0, 3, 4, 9],\n",
    "                       [3, 0, 2, 4],\n",
    "                       [4, 2, 0, 4],\n",
    "                       [9, 4, 4, 0]])\n",
    "\n",
    "N_SPECIES = STEP_MATRIX.shape[0]\n",
    "\n",
    "STR_JOIN = \"+\"\n",
    "\n",
    "CHAR_ORDER = [\"A\", \"C\", \"G\", \"T\"]\n",
    "\n",
    "DIC1 = {\n",
    "          'Probopass':np.array([0,np.inf,np.inf,np.inf]),\n",
    "          'Aggron':np.array([np.inf,np.inf,np.inf,0]),\n",
    "          'Bastiodon':np.array([np.inf,np.inf,np.inf,0]),\n",
    "          'Regirock':np.array([np.inf,np.inf,0,np.inf]),\n",
    "          'Registeel':np.array([np.inf,np.inf,0,np.inf]),\n",
    "          'Regice':np.array([np.inf,np.inf,0,np.inf]),\n",
    "          'Klingklang':np.array([np.inf,np.inf,0,np.inf]),\n",
    "          'Metagross':np.array([np.inf,0,np.inf,np.inf]),\n",
    "          'Genesect':np.array([0,np.inf,np.inf,np.inf]),\n",
    "          'Porygon=Z':np.array([np.inf,0,np.inf,np.inf]),\n",
    "          'Magnezone':np.array([np.inf,0,np.inf,np.inf]),\n",
    "          'Forretress':np.array([np.inf,np.inf,np.inf,0]),\n",
    "          'Electrode':np.array([0,np.inf,np.inf,np.inf]),\n",
    "          'Ferrothorn':np.array([np.inf,np.inf,0,np.inf]),\n",
    "       }\n",
    "\n",
    "N1 = \"(((( Electrode , Magnezone) ,Porygon=Z) , (((( Aggron , Bastiodon ) , Forretress ) , Ferrothorn ) , ((((( Regirock , Regice ) , Registeel ) , Metagross ) , Klingklang ) , Genesect ))) , Probopass );\"\n",
    "N2 = \"((((( Regirock , Regice ) , Registeel ) , (( Metagross , Klingklang ) , Genesect )) , ((( Aggron , Bastiodon ) ,( Forretress , Ferrothorn )) , Probopass )) ,( Porygon=Z,( Magnezone , Electrode )));\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"tree1.png\" width=\"500px\">\n",
    "<img src=\"tree2.png\" width=\"500px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((( Electrode , Magnezone) ,Porygon=Z) , (((( Aggron , Bastiodon ) , Forretress ) , Ferrothorn ) , ((((( Regirock , Regice ) , Registeel ) , Metagross ) , Klingklang ) , Genesect ))) , Probopass );\n",
      "\n",
      "            /-Electrode\n",
      "         /-|\n",
      "      /-|   \\-Magnezone\n",
      "     |  |\n",
      "     |   \\-Porygon=Z\n",
      "     |\n",
      "     |            /-Aggron\n",
      "     |         /-|\n",
      "     |      /-|   \\-Bastiodon\n",
      "   /-|     |  |\n",
      "  |  |   /-|   \\-Forretress\n",
      "  |  |  |  |\n",
      "  |  |  |   \\-Ferrothorn\n",
      "  |  |  |\n",
      "  |  |  |               /-Regirock\n",
      "  |  |  |            /-|\n",
      "  |   \\-|         /-|   \\-Regice\n",
      "--|     |        |  |\n",
      "  |     |      /-|   \\-Registeel\n",
      "  |     |     |  |\n",
      "  |     |   /-|   \\-Metagross\n",
      "  |     |  |  |\n",
      "  |      \\-|   \\-Klingklang\n",
      "  |        |\n",
      "  |         \\-Genesect\n",
      "  |\n",
      "   \\-Probopass\n"
     ]
    }
   ],
   "source": [
    "tree1 = Tree(N1)\n",
    "print(N1)\n",
    "print(tree1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sankoff algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Ca aurait du être beaucoup plus simple et beaucoup moins long, je m'en suis rendu compte mais je voulais voir si j'étais capable de réussir en continuant sur ma premiere intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sankoff(tree):\n",
    "    init_solo_leaves() # Initialisation of the solo leaves for the traceback function\n",
    "    new_tree = parse_string(tree) # In this part we clean and parse the string to get an array\n",
    "    merge_cluster(new_tree) # In this part we merge the clusters and add the new array values of intern nodes in the dictionnary\n",
    "    new_chars = traceback() # Traceback in the dictionnary and gets the new characters of the nodes\n",
    "    new_dic = update_dic(new_chars)\n",
    "    parcimony_score = compute_score(new_chars, new_dic) # Computes the parcimony score of the tree\n",
    "    return new_dic, parcimony_score\n",
    "\n",
    "def parse_string(tree):\n",
    "    tree = tree.replace(\" \",\"\")\n",
    "    tree = tree.replace(\";\",\"\")\n",
    "    new_tree = []\n",
    "    for i in range(len(tree)):\n",
    "        if tree[i] == \")\":\n",
    "            cpt = 0\n",
    "            for j in range(i, 0, -2):\n",
    "                if tree[j] == \")\" and tree[j-1] == \")\": # Discriminate mini/big cluster and get offset\n",
    "                    cpt += 1\n",
    "            tmp_tree = tree[:i] # Cut after parenthesis\n",
    "            n_close_par = tmp_tree.count(\")\") # Counts open and close parenthesis\n",
    "            n_open_par = tmp_tree.count(\"(\")\n",
    "            if cpt == 1: # Big cluster\n",
    "                parenthesis_to_cut = n_open_par - n_close_par + cpt + 1 # FIX BUG HERE WITH N2\n",
    "                nth = find_nth(tmp_tree, \"(\", parenthesis_to_cut) # Finds the index to cut at the right open parenthesis\n",
    "                tmp_tree = tmp_tree[nth:] \n",
    "            else: # Mini cluster\n",
    "                index_par = tmp_tree.rfind(\"(\") # For mini cluster : just cut at first open parenthesis met\n",
    "                tmp_tree = tmp_tree[index_par:]\n",
    "            tmp_tree = tmp_tree.replace(\"(\",\"\") # Delete all parenthesis to extract leaves\n",
    "            tmp_tree = tmp_tree.replace(\")\",\"\")\n",
    "            leaves = tmp_tree.split(\",\")\n",
    "            new_tree.append(leaves) # We build a new list of list containing leaves\n",
    "    return new_tree\n",
    "\n",
    "def merge_cluster(new_tree):\n",
    "    visited = []\n",
    "#     species = np.unique(np.concatenate(np.array(new_tree)).flatten()) # Gets the species of the tree\n",
    "    for i in range(len(new_tree)):\n",
    "        if len(new_tree[i]) == 2: # Merge of 2 elements\n",
    "            elt1 = new_tree[i][0]\n",
    "            elt2 = new_tree[i][1]\n",
    "            new_ancester = add_ancester(elt1, elt2)\n",
    "            visited.append(new_ancester)\n",
    "        else: # Merge of clusters\n",
    "            tmp_str = new_tree[i][0]\n",
    "            str_possible = []\n",
    "            for j in range(1, len(new_tree[i])-1):\n",
    "                tmp_str += STR_JOIN + new_tree[i][j]\n",
    "                str_possible.append(tmp_str)\n",
    "            str_possible.reverse() # All the existing clusters in this array\n",
    "            if tmp_str in visited: # Merge of mini clusters\n",
    "                visited.remove(tmp_str) # If we find one we remove it from the visited array\n",
    "                del_elt = tmp_str.split(STR_JOIN)\n",
    "                new_elt = new_tree[i].copy() # Copy because we remove from new_elt after that\n",
    "                for elt in del_elt:\n",
    "                    new_elt.remove(elt)\n",
    "                new_ancester = add_ancester(tmp_str, new_elt[0])\n",
    "                visited.append(new_ancester)\n",
    "            else: # Merge of big clusters\n",
    "                str_possible = []\n",
    "                for j in range(1, len(new_tree[i])):\n",
    "                    tmp_str += STR_JOIN + new_tree[i][j]\n",
    "                    str_possible.append(tmp_str)\n",
    "                str_possible.reverse() \n",
    "                new_list = []\n",
    "                for j in range(len(visited)):\n",
    "                    if visited[j] in tmp_str: # This time there can be multiple clusters\n",
    "                        new_list.append(visited[j])\n",
    "                new_ancester = add_ancester(new_list[0], new_list[1])\n",
    "                visited.append(new_ancester)\n",
    "                visited.remove(new_list[0])\n",
    "                visited.remove(new_list[1])\n",
    "    \n",
    "def find_nth(haystack, needle, n):\n",
    "    start = haystack.find(needle)\n",
    "    while start >= 0 and n > 1:\n",
    "        start = haystack.find(needle, start+len(needle))\n",
    "        n -= 1\n",
    "    return start\n",
    "    \n",
    "def add_ancester(elt1, elt2):\n",
    "    new_ancester = elt1+STR_JOIN+elt2 \n",
    "    if len(DIC1[elt1]) != 4: # Have to check if we just have the basic array\n",
    "        val1 = DIC1[elt1][0] # or if we have the array + backtrack characters\n",
    "    else:\n",
    "        val1 = DIC1[elt1]\n",
    "    if len(DIC1[elt2]) != 4:\n",
    "        val2 = DIC1[elt2][0]\n",
    "    else:\n",
    "        val2 = DIC1[elt2]\n",
    "    new_values = compute_new_values(val1, val2)\n",
    "    add_to_backtrack_dic(val1, val2, new_ancester, new_values)\n",
    "    return new_ancester\n",
    "    \n",
    "def compute_new_values(val1, val2):\n",
    "    new_array = np.zeros((N_SPECIES))\n",
    "    for i in range(N_SPECIES):\n",
    "        new_array[i] = np.min(STEP_MATRIX[i]+val1) + np.min(STEP_MATRIX[i]+val2)\n",
    "    return new_array\n",
    "\n",
    "def add_to_backtrack_dic(val1, val2, new_ancester, new_values):\n",
    "    min_index1, min_index2 = np.argmin(val1), np.argmin(val2)\n",
    "    DIC1[new_ancester] = [new_values, CHAR_ORDER[min_index1], CHAR_ORDER[min_index2]] \n",
    "    \n",
    "def init_solo_leaves():\n",
    "    for key in DIC1:\n",
    "        if STR_JOIN not in key:\n",
    "            DIC1[key] = [DIC1[key], CHAR_ORDER[np.argmin(DIC1[key])]]\n",
    "\n",
    "def get_parent(dic, child):\n",
    "    for k in dic.keys():\n",
    "        if child + STR_JOIN + k in dic.keys():\n",
    "            return child + STR_JOIN + k\n",
    "        elif k + STR_JOIN + child in dic.keys():\n",
    "            return k + STR_JOIN + child\n",
    "    return child\n",
    "\n",
    "def copy_dic(dic):\n",
    "    new_dic = {}\n",
    "    for key, value in dic.items():\n",
    "        new_dic[key] = value\n",
    "    return new_dic\n",
    "\n",
    "def traceback():\n",
    "    new_chars = []\n",
    "    first_elem = True\n",
    "    dic_save = copy_dic(DIC1) # Copy not working ? Function copy() not working either ? Have to mutate the global DIC...\n",
    "    for key, item in reversed(DIC1.items()): # The values are already possible values for the final one\n",
    "        tmp_item = item[1:] # Ignoring array values\n",
    "        if len(tmp_item) == 2 and tmp_item[0] == tmp_item[1]: # When we have to chose between same letters\n",
    "            element_to_add = tmp_item[0] # we have pick the first one\n",
    "            dic_save[key].remove(tmp_item[1]) # and delete the other one\n",
    "        else:\n",
    "            if STR_JOIN in key: # If its not a leaf we need to chose a character\n",
    "                if first_elem: # Chose character randomly for the first node\n",
    "                    element_to_add = tmp_item[1]\n",
    "                    first_elem = False\n",
    "                else: # If it's not the first node\n",
    "                    for elt in tmp_item: # For each element in the list\n",
    "                        tmp_parent = get_parent(dic_save, key) # Get the parent of the key to check if the element can be chosen according to its parent\n",
    "                        if elt in dic_save[tmp_parent]: # If the element is the same than one of the parent one \n",
    "                            element_to_add = elt # Then we append it\n",
    "                            break\n",
    "                        else:\n",
    "                            element_to_add = tmp_item[1]\n",
    "                            break\n",
    "            else: # If its a leaf we just copy the value\n",
    "                element_to_add = tmp_item[0]  \n",
    "        new_chars.append(element_to_add)\n",
    "        if len(dic_save[key]) > 2: # This block deletes the element that is not selected by the previous conditions\n",
    "            for element in dic_save[key]:\n",
    "                if len(element) != 4 and element != element_to_add:\n",
    "                    dic_save[key].remove(element)\n",
    "    return new_chars\n",
    "\n",
    "def update_dic(new_chars):\n",
    "    new_dic = {}\n",
    "    index = 0\n",
    "    for key in reversed(DIC1):\n",
    "        new_dic[key] = new_chars[index]\n",
    "        index += 1\n",
    "    return new_dic\n",
    "\n",
    "def compute_score(new_chars, new_dic):\n",
    "    score = 0\n",
    "    for k1 in new_dic.keys():\n",
    "        for k2 in new_dic.keys():\n",
    "            if k1 + STR_JOIN + k2 in new_dic.keys(): # If k1 and k2 are leaves\n",
    "                if new_dic[k1] != new_dic[k1 + STR_JOIN + k2]: # Then check if their values are the same as their parents\n",
    "                    score += 1\n",
    "                if new_dic[k2] != new_dic[k1 + STR_JOIN + k2]:\n",
    "                    score += 1\n",
    "    return score\n",
    "\n",
    "# Forgot a dictionnary isn't ordered :) \n",
    "# def order_dic(dic): # Reversing parsing function to find the right connections between nodes\n",
    "#     couples = []\n",
    "#     parent = []\n",
    "#     for key in reversed(dic):\n",
    "#         for elt in reversed(dic.keys()):\n",
    "#             if elt in key and elt != key: # We find the biggest child thanks to the reversed key\n",
    "#                 elt1 = elt # The first element is the big one\n",
    "#                 elt2 = key.replace(elt, \"\") # The second element is the remaining node\n",
    "#                 if elt2[0] == STR_JOIN:\n",
    "#                     elt2 = elt2[1:]\n",
    "#                 if elt2[-1] == STR_JOIN:\n",
    "#                     elt2 = elt2[:-1]\n",
    "#                 parent.append(dic[elt])\n",
    "#                 couples.append([elt1, elt2])\n",
    "#                 break\n",
    "#     flatten_couples = []\n",
    "#     for i in range(len(couples)): # Flatten the array\n",
    "#         flatten_couples.append(couples[i][0])\n",
    "#         flatten_couples.append(couples[i][1])\n",
    "#     new_dic = {}\n",
    "#     first_elem = True\n",
    "#     for node in flatten_couples: # Use the flattened array order to sort the dic\n",
    "#         for key in reversed(dic): \n",
    "#             if first_elem: # Init with first value\n",
    "#                 new_dic[key] = dic[key]\n",
    "#                 first_elem = False\n",
    "#             if node == key:\n",
    "#                 new_dic[key] = dic[key]\n",
    "#     return new_dic, parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result for N1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parcimony score N1: 6\n",
      "Dictionnary after sankoff process on N1:\n",
      "{'Probopass': [array([ 0., inf, inf, inf]), 'A'],\n",
      " 'Aggron': [array([inf, inf, inf,  0.]), 'T'],\n",
      " 'Bastiodon': [array([inf, inf, inf,  0.]), 'T'],\n",
      " 'Regirock': [array([inf, inf,  0., inf]), 'G'],\n",
      " 'Registeel': [array([inf, inf,  0., inf]), 'G'],\n",
      " 'Regice': [array([inf, inf,  0., inf]), 'G'],\n",
      " 'Klingklang': [array([inf, inf,  0., inf]), 'G'],\n",
      " 'Metagross': [array([inf,  0., inf, inf]), 'C'],\n",
      " 'Genesect': [array([ 0., inf, inf, inf]), 'A'],\n",
      " 'Porygon=Z': [array([inf,  0., inf, inf]), 'C'],\n",
      " 'Magnezone': [array([inf,  0., inf, inf]), 'C'],\n",
      " 'Forretress': [array([inf, inf, inf,  0.]), 'T'],\n",
      " 'Electrode': [array([ 0., inf, inf, inf]), 'A'],\n",
      " 'Ferrothorn': [array([inf, inf,  0., inf]), 'G'],\n",
      " 'Electrode+Magnezone': [array([ 3.,  3.,  6., 13.]), 'C'],\n",
      " 'Electrode+Magnezone+Porygon=Z': [array([ 6.,  3.,  7., 11.]), 'C'],\n",
      " 'Aggron+Bastiodon': [array([18.,  8.,  8.,  0.]), 'T'],\n",
      " 'Aggron+Bastiodon+Forretress': [array([18.,  8.,  8.,  0.]), 'T'],\n",
      " 'Aggron+Bastiodon+Forretress+Ferrothorn': [array([13.,  6.,  4.,  4.]), 'G'],\n",
      " 'Regirock+Regice': [array([8., 4., 0., 8.]), 'G'],\n",
      " 'Regirock+Regice+Registeel': [array([8., 4., 0., 8.]), 'G'],\n",
      " 'Regirock+Regice+Registeel+Metagross': [array([7., 2., 2., 8.]), 'G'],\n",
      " 'Regirock+Regice+Registeel+Metagross+Klingklang': [array([ 9.,  4.,  2., 10.]),\n",
      "                                                    'G'],\n",
      " 'Regirock+Regice+Registeel+Metagross+Klingklang+Genesect': [array([ 6.,  7.,  6., 15.]),\n",
      "                                                             'G'],\n",
      " 'Aggron+Bastiodon+Forretress+Ferrothorn+Regirock+Regice+Registeel+Metagross+Klingklang+Genesect': [array([14., 13., 10., 14.]),\n",
      "                                                                                                    'G'],\n",
      " 'Electrode+Magnezone+Porygon=Z+Aggron+Bastiodon+Forretress+Ferrothorn+Regirock+Regice+Registeel+Metagross+Klingklang+Genesect': [array([20., 15., 15., 21.]),\n",
      "                                                                                                                                  'G'],\n",
      " 'Electrode+Magnezone+Porygon=Z+Aggron+Bastiodon+Forretress+Ferrothorn+Regirock+Regice+Registeel+Metagross+Klingklang+Genesect+Probopass': [array([18., 18., 19., 28.]),\n",
      "                                                                                                                                            'A']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-355cb0c18e75>:154: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  dic_save[key].remove(element)\n",
      "<ipython-input-4-355cb0c18e75>:142: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if elt in dic_save[tmp_parent]: # If the element is the same than one of the parent one\n",
      "<ipython-input-4-355cb0c18e75>:133: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  dic_save[key].remove(tmp_item[1]) # and delete the other one\n"
     ]
    }
   ],
   "source": [
    "new_dic1, parcimony_score1 = sankoff(N1)\n",
    "print(\"Parcimony score N1:\", parcimony_score1)\n",
    "print(\"Dictionnary after sankoff process on N1:\")\n",
    "pprint.pprint(DIC1, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset of the global variable DIC1 because we removed items while processing N1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIC1 = {\n",
    "          'Probopass':np.array([0,np.inf,np.inf,np.inf]),\n",
    "          'Aggron':np.array([np.inf,np.inf,np.inf,0]),\n",
    "          'Bastiodon':np.array([np.inf,np.inf,np.inf,0]),\n",
    "          'Regirock':np.array([np.inf,np.inf,0,np.inf]),\n",
    "          'Registeel':np.array([np.inf,np.inf,0,np.inf]),\n",
    "          'Regice':np.array([np.inf,np.inf,0,np.inf]),\n",
    "          'Klingklang':np.array([np.inf,np.inf,0,np.inf]),\n",
    "          'Metagross':np.array([np.inf,0,np.inf,np.inf]),\n",
    "          'Genesect':np.array([0,np.inf,np.inf,np.inf]),\n",
    "          'Porygon=Z':np.array([np.inf,0,np.inf,np.inf]),\n",
    "          'Magnezone':np.array([np.inf,0,np.inf,np.inf]),\n",
    "          'Forretress':np.array([np.inf,np.inf,np.inf,0]),\n",
    "          'Electrode':np.array([0,np.inf,np.inf,np.inf]),\n",
    "          'Ferrothorn':np.array([np.inf,np.inf,0,np.inf]),\n",
    "       }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result for N2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parcimony score N2: 7\n",
      "Dictionnary after sankoff process on N2:\n",
      "{'Regirock+Regice+Registeel+Metagross+Klingklang+Genesect+Aggron+Bastiodon': 'T',\n",
      " 'Magnezone+Electrode': 'C',\n",
      " 'Forretress+Ferrothorn+Probopass': 'G',\n",
      " 'Forretress+Ferrothorn': 'G',\n",
      " 'Aggron+Bastiodon': 'T',\n",
      " 'Regirock+Regice+Registeel+Metagross+Klingklang+Genesect': 'A',\n",
      " 'Metagross+Klingklang+Genesect': 'A',\n",
      " 'Metagross+Klingklang': 'G',\n",
      " 'Regirock+Regice+Registeel': 'G',\n",
      " 'Regirock+Regice': 'G',\n",
      " 'Ferrothorn': 'G',\n",
      " 'Electrode': 'A',\n",
      " 'Forretress': 'T',\n",
      " 'Magnezone': 'C',\n",
      " 'Porygon=Z': 'C',\n",
      " 'Genesect': 'A',\n",
      " 'Metagross': 'C',\n",
      " 'Klingklang': 'G',\n",
      " 'Regice': 'G',\n",
      " 'Registeel': 'G',\n",
      " 'Regirock': 'G',\n",
      " 'Bastiodon': 'T',\n",
      " 'Aggron': 'T',\n",
      " 'Probopass': 'A'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-355cb0c18e75>:154: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  dic_save[key].remove(element)\n",
      "<ipython-input-4-355cb0c18e75>:142: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if elt in dic_save[tmp_parent]: # If the element is the same than one of the parent one\n",
      "<ipython-input-4-355cb0c18e75>:133: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  dic_save[key].remove(tmp_item[1]) # and delete the other one\n"
     ]
    }
   ],
   "source": [
    "new_dic2, parcimony_score2 = sankoff(N2)\n",
    "print(\"Parcimony score N2:\", parcimony_score2)\n",
    "print(\"Dictionnary after sankoff process on N2:\")\n",
    "pprint.pprint(new_dic2, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The parsimony score is the lowest for N1, which means that the first tree is more likely."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
