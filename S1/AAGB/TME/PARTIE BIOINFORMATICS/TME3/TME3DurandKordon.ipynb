{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ete3 import Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_matrix = np.array([[0, 3, 4, 9],\n",
    "                       [3, 0, 2, 4],\n",
    "                       [4, 2, 0, 4],\n",
    "                       [9, 4, 4, 0]])\n",
    "\n",
    "n_species = step_matrix.shape[0]\n",
    "\n",
    "# Ordre : A C G T\n",
    "dic1 = {\n",
    "          'Probopass':np.array([0,np.inf,np.inf,np.inf]),\n",
    "          'Aggron':np.array([np.inf,np.inf,np.inf,0]),\n",
    "          'Bastiodon':np.array([np.inf,np.inf,np.inf,0]),\n",
    "          'Regirock':np.array([np.inf,np.inf,0,np.inf]),\n",
    "          'Registeel':np.array([np.inf,np.inf,0,np.inf]),\n",
    "          'Regice':np.array([np.inf,np.inf,0,np.inf]),\n",
    "          'Klingklang':np.array([np.inf,np.inf,0,np.inf]),\n",
    "          'Metagross':np.array([np.inf,0,np.inf,np.inf]),\n",
    "          'Genesect':np.array([0,np.inf,np.inf,np.inf]),\n",
    "          'Porygon=Z':np.array([np.inf,0,np.inf,np.inf]),\n",
    "          'Magnezone':np.array([np.inf,0,np.inf,np.inf]),\n",
    "          'Forretress':np.array([np.inf,np.inf,np.inf,0]),\n",
    "          'Electrode':np.array([0,np.inf,np.inf,np.inf]),\n",
    "          'Ferrothorn':np.array([np.inf,np.inf,0,np.inf]),\n",
    "       }\n",
    "\n",
    "N1 = \"(((( Electrode , Magnezone) ,Porygon=Z) , (((( Aggron , Bastiodon ) , Forretress ) , Ferrothorn ) , ((((( Regirock , Regice ) , Registeel ) , Metagross ) , Klingklang ) , Genesect ))) , Probopass );\"\n",
    "N2 = \"((((( Regirock , Regice ) , Registeel ) , (( Metagross , Klingklang ) , Genesect )) , ((( Aggron , Bastiodon ) ,( Forretress , Ferrothorn )) , Probopass )) ,( Porygon=Z,( Magnezone , Electrode )));\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"tree1.png\" width=\"500px\">\n",
    "<img src=\"tree2.png\" width=\"500px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sankoff algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 = Tree(N1)\n",
    "print(N1)\n",
    "print(tree1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_string(tree):\n",
    "    tree = tree.replace(\" \",\"\")\n",
    "    tree = tree.replace(\";\",\"\")\n",
    "    new_tree = []\n",
    "    for i in range(len(tree)):\n",
    "        if tree[i] == \")\":\n",
    "            cpt = 0\n",
    "            for j in range(i, 0, -2):\n",
    "                if tree[j] == \")\" and tree[j-1] == \")\": # Discriminate mini/big cluster and get offset\n",
    "                    cpt += 1\n",
    "            tmp_tree = tree[:i] # Cut after parenthesis\n",
    "            n_close_par = tmp_tree.count(\")\") # Counts open and close parenthesis\n",
    "            n_open_par = tmp_tree.count(\"(\")\n",
    "            if cpt == 1: # Big cluster\n",
    "                parenthesis_to_cut = n_open_par - n_close_par + cpt + 1 # Petit bug de decalage ici avec N2 ...\n",
    "                nth = find_nth(tmp_tree, \"(\", parenthesis_to_cut) # Finds the index to cut at the right open parenthesis\n",
    "                tmp_tree = tmp_tree[nth:] \n",
    "            else: # Mini cluster\n",
    "                index_par = tmp_tree.rfind(\"(\") # For mini cluster : just cut at first open parenthesis met\n",
    "                tmp_tree = tmp_tree[index_par:]\n",
    "            tmp_tree = tmp_tree.replace(\"(\",\"\") # Delete all parenthesis to extract leaves\n",
    "            tmp_tree = tmp_tree.replace(\")\",\"\")\n",
    "            leaves = tmp_tree.split(\",\")\n",
    "            new_tree.append(leaves) # We build a new list of list containing leaves\n",
    "    return new_tree\n",
    "\n",
    "def merge_cluster(new_tree):\n",
    "    visited = []\n",
    "#     species = np.unique(np.concatenate(np.array(new_tree)).flatten()) # Gets the species of the tree\n",
    "    for i in range(len(new_tree)):\n",
    "        if len(new_tree[i]) == 2: # Merge of 2 elements\n",
    "            elt1 = new_tree[i][0]\n",
    "            elt2 = new_tree[i][1]\n",
    "#             print(\"we add\", elt1, \"and\", elt2)\n",
    "            new_ancester = add_ancester(elt1, elt2)\n",
    "            visited.append(new_ancester)\n",
    "        else: # Merge of clusters\n",
    "            tmp_str = new_tree[i][0]\n",
    "            str_possible = []\n",
    "            for j in range(1, len(new_tree[i])-1):\n",
    "                tmp_str += \"-\" + new_tree[i][j]\n",
    "                str_possible.append(tmp_str)\n",
    "            str_possible.reverse() # All the existing clusters in this array\n",
    "            if tmp_str in visited: # Merge of mini clusters\n",
    "                visited.remove(tmp_str) # If we find one we remove it from the visited array\n",
    "                del_elt = tmp_str.split(\"-\")\n",
    "                new_elt = new_tree[i].copy() # Copy because we remove from new_elt after that\n",
    "                for elt in del_elt:\n",
    "                    new_elt.remove(elt)\n",
    "#                 print(\"we add\", tmp_str, \"and\", new_elt[0])\n",
    "                new_ancester = add_ancester(tmp_str, new_elt[0])\n",
    "                visited.append(new_ancester)\n",
    "            else: # Merge of big clusters\n",
    "                str_possible = []\n",
    "                for j in range(1, len(new_tree[i])):\n",
    "                    tmp_str += \"-\" + new_tree[i][j]\n",
    "                    str_possible.append(tmp_str)\n",
    "                str_possible.reverse() \n",
    "                new_list = []\n",
    "                for j in range(len(visited)):\n",
    "                    if visited[j] in tmp_str: # This time there can be multiple clusters\n",
    "                        new_list.append(visited[j])\n",
    "#                 print(\"we add\", new_list[0], \"and\", new_list[1])\n",
    "                new_ancester = add_ancester(new_list[0], new_list[1])\n",
    "                visited.append(new_ancester)\n",
    "                visited.remove(new_list[0])\n",
    "                visited.remove(new_list[1])\n",
    "\n",
    "def sankoff(tree):\n",
    "    # In this part we clean and parse the string to get an array\n",
    "    new_tree = parse_string(tree)\n",
    "    # In this part we merge the clusters        \n",
    "    merge_cluster(new_tree)\n",
    "    \n",
    "def find_nth(haystack, needle, n):\n",
    "    start = haystack.find(needle)\n",
    "    while start >= 0 and n > 1:\n",
    "        start = haystack.find(needle, start+len(needle))\n",
    "        n -= 1\n",
    "    return start\n",
    "    \n",
    "def add_ancester(elt1, elt2):\n",
    "    new_ancester = elt1+\"-\"+elt2    \n",
    "    new_tab = compute_new_values(elt1,elt2)\n",
    "    dic1[new_ancester] = new_tab\n",
    "    return new_ancester\n",
    "    \n",
    "def compute_new_values(elt1,elt2):\n",
    "    new_tab = np.zeros((n_species))\n",
    "    val1 = dic1[elt1]\n",
    "    val2 = dic1[elt2]\n",
    "    for i in range(n_species):\n",
    "        val_letter = step_matrix[i]\n",
    "        new_tab[i] = np.min(val_letter+val1) + np.min(val_letter+val2)\n",
    "    return new_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(N1.replace(\" \", \"\"))\n",
    "sankoff(N1)\n",
    "print(dic1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
