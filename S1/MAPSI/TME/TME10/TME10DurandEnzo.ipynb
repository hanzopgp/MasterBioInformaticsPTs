{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TME 10 : méthodes discriminantes\n",
    "\n",
    "Le but de ce TME est de comparer les approches en modélisation maximum de vraisemblance et maximum a posteriori au niveau de la modélisation même du problème dans le cas de la classification. \n",
    "\n",
    "Nous notons  les observations $\\mathbf x_i \\in \\mathbb R^d$ et les étiquettes binaires associées $y_{i} \\in \\mathcal Y = \\{0, 1\\}$.\n",
    "Nous faisons l'hypothèse que les couples $(\\mathbf x_i, y_{i})$ sont tirés de manière i.i.d. et suivent une loi inconnue $P(X,Y)$. \n",
    "\n",
    "***Résumé du max de vraisemblance:***<BR>\n",
    "1. Choix d'une modélisation $\\Theta$ pour les $\\mathbf x_i$ (par exemple une gaussienne multivariée ou une modélisation dimension par dimension selon une loi choisie en accord avec les experts du domaine).\n",
    "1. Formalisation de la vraisemblance pour un échantillon:\n",
    "$p(\\mathbf x_i | \\Theta)$\n",
    "1. Pour chaque classe $y$ (0 ou 1 dans le cas présent), optimisation de \n",
    "    $$\\Theta_y^\\star = \\arg \\max_{\\Theta} \\prod_{i \\in y} p(\\mathbf x_i | \\Theta)$$\n",
    "1. Critère de décision pour un nouvel échantillon $\\mathbf x_n$:\n",
    "    $$\\hat y_n = \\arg \\max_c p(\\mathbf x_n | \\Theta_y) $$\n",
    "\n",
    "La méthode est simple et efficace mais ne compare jamais les échantillons des différentes classes pour prendre une décision.\n",
    "\n",
    "***Idée des approches discriminantes:***<BR>\n",
    "1. Choix d'un modèle pour $p(y_i | \\mathbf x_i)$. Le modèle le plus connu est la régression logistique qui, comme le nom ne l'indique pas est un modèle de classification. C'est ce modèle que nous allons étudier:\n",
    "    $$p(y_i=1 | \\mathbf x_i) = \\frac{1}{1 + \\exp( -(  \\mathbf x_i  \\mathbf w + b))},\\qquad \\mbox{Paramètres : } \\mathbf w, b $$\n",
    "1. Dans le cas à deux classes uniquement; après avoir remarqué que nous avons choisi un codage des classes de type Bernoulli... Utilisation de l'astuce de Bernoulli pour calculer la vraisemblance d'un échantillon:\n",
    "$$ p(y_i | \\mathbf x_i) = \\left( \\frac{1}{1 + \\exp( -(  \\mathbf x_i  \\mathbf w + b))}\\right)^{y_i} \\left(1- \\frac{1}{1 + \\exp( -(  \\mathbf x_i  \\mathbf w + b))}\\right)^{1-y_i} $$\n",
    "1. Max de vraisemblance sur ***sur l'ensemble des données***:\n",
    "    $$\\mathbf w^\\star, b^\\star = \\arg \\max_{\\mathbf w, b} \\prod_{i} p(\\mathbf x_i, y_i | \\mathbf w, b) = \\arg \\max_{\\mathbf w, b} \\prod_{i} p( y_i|\\mathbf x_i, \\mathbf w, b) p(\\mathbf x_i| \\mathbf w, b)$$\n",
    "En faisant l'hypothèse que les $\\mathbf x_i$ sont équiprobables (pas de poids sur les observations):\n",
    "$$\\mathbf w^\\star, b^\\star = \\arg \\max_{\\mathbf w, b} \\prod_{i} p( y_i|\\mathbf x_i, \\mathbf w, b)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des librairies et des données USPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "def load(filename):\n",
    "    f=open(filename,'r')\n",
    "    s = f.readline() # virer la premiere ligne\n",
    "    X = np.array([[float(d) for d in lig.split()] for lig in f if len(lig)>10])\n",
    "    Y = X[:,0] # premiere colonne\n",
    "    X = X[:,1:]\n",
    "    f.close()\n",
    "    return X,Y\n",
    "\n",
    "X,Y = load('data/usps_train.txt')\n",
    "Xt,Yt = load('data/usps_test.txt')\n",
    "\n",
    "# affichage d'un échantillon\n",
    "plt.figure()\n",
    "index = 0\n",
    "plt.imshow(X[index].reshape(16,16), interpolation=None)\n",
    "plt.title('Affichage d\\'un échantillon de la classe: '+str(Y[index]))\n",
    "\n",
    "# étude très rapide des données:\n",
    "plt.figure()\n",
    "plt.hist(Y, 10) # histogramme de répartition des 10 classes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1: retour sur le max de vraisemblance\n",
    "\n",
    "Nous retravaillons rapidement le max de vraisemblance pour obtenir un baseline. Nous allons travailler en bayesien naif sur des images binarisées:\n",
    "$$ x_{ij} \\in \\{0,1\\}, \\qquad p(x_i | \\Theta) = \\prod_j p(x_{ij} | \\Theta_j)$$\n",
    "\n",
    "Le code est fourni, il suffit de l'exécuter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apprentissage d'un modèle de Bernoulli naif par classe\n",
    "def learnBernoulli (X,Y):\n",
    "    theta = [(X[Y==y].mean(0)) for y in np.unique(Y)]\n",
    "    return np.array(theta)\n",
    "\n",
    "# evaluation de la vraisemblance d'une base d'échantillon\n",
    "# retourne une matrice avec les vraisemblances des échantillons pour toutes les classes\n",
    "def logpobsBernoulli(X, theta):\n",
    "    seuil = 1e-4\n",
    "    theta = np.maximum(np.minimum(1-seuil, theta),seuil)\n",
    "    logp = [[ (x*np.log(mod)+(1-x)*np.log(1-mod)).sum() for x in X] for mod in theta ]\n",
    "    return np.array(logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli : Taux bonne classification en apprentissage :  0.8723083253326018\n",
      "Bernoulli : Taux bonne classification en test :  0.8236173393124065\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# binariser X (sinon la modélisation Bernoulli ne tient plus)\n",
    "Xb = np.where(X >0, 1., 0.)\n",
    "Xbt = np.where(Xt >0, 1., 0.)\n",
    "\n",
    "\n",
    "## Max de Vraisemblance\n",
    "theta = learnBernoulli ( Xb,Y )\n",
    "## Evaluation de la vraisemblance des échantillons\n",
    "logp  = logpobsBernoulli(Xb, theta)\n",
    "logpT = logpobsBernoulli(Xbt, theta)\n",
    "\n",
    "# calcul des y de prédiction à partir de la matrice des vraisemblances\n",
    "ypred_b  = logp.argmax(0)\n",
    "ypredT_b = logpT.argmax(0)\n",
    "\n",
    "print(\"Bernoulli : Taux bonne classification en apprentissage : \",np.where(ypred_b != Y, 0.,1.).mean())\n",
    "print(\"Bernoulli : Taux bonne classification en test : \",np.where(ypredT_b != Yt, 0.,1.).mean())\n",
    "\n",
    "# resultats qualitatifs: affichage des poids du modèle de la classe 0\n",
    "plt.figure()\n",
    "plt.imshow(theta[0].reshape(16,16))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2: prise en compte des informations a priori et passage au MAP\n",
    "\n",
    "La seule information dont nous disposons est la répartition des classes (cf histogramme).\n",
    "1. Calcul des probabilités a priori des classes \n",
    "1. Evaluation des performances avec prise en compte de ces informations a priori\n",
    "1. Afficher les images des chiffres qui changent de classe avec les prédictions avant/après\n",
    "\n",
    "Cet exercice correspondant principalement à des compétences de séances précédentes, le code est fourni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli : Taux bonne classification MAP en apprentissage :  0.8720340145384721\n",
      "Bernoulli : Taux bonne classification MAP en test :  0.8236173393124065\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CORRECTION\n",
    "pAPriori = np.array([np.where(Y==i, 1, 0).sum() for i in np.unique(Y)]).reshape(10,1) / len(Y)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(pAPriori.T, interpolation=None)\n",
    "plt.title('Distribution des classes')\n",
    "\n",
    "# pas de modification sur les paramètres optimaux\n",
    "ypred  = (logp + np.log(pAPriori)).argmax(0) # utilise le dispatch numpy\n",
    "ypredT = (logpT+ np.log(pAPriori)).argmax(0)\n",
    "\n",
    "print (\"Bernoulli : Taux bonne classification MAP en apprentissage : \",np.where(ypred != Y, 0.,1.).mean())\n",
    "print (\"Bernoulli : Taux bonne classification MAP en test : \",np.where(ypredT != Yt, 0.,1.).mean())\n",
    "\n",
    "# recherche d'un point ayant changé de classe avec le MAP:\n",
    "index = np.where(ypred != ypred_b)[0]\n",
    "plt.figure()\n",
    "plt.subplots(1,len(index))\n",
    "for num,i in enumerate(index):\n",
    "    plt.subplot(1,len(index),num+1) # subplot commence à 1 (héritage matlab)\n",
    "    plt.imshow(Xb[i].reshape(16,16))\n",
    "    plt.title(\"y = \"+str(int(Y[i])) + \",\"+str(ypred[i])+\",\"+str(ypred_b[i]) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3: codage de la régression logistique\n",
    "\n",
    "***Rappel: régression logistique = système de classification***\n",
    "\n",
    "$$ p(y_i | \\mathbf x_i) = \\left( \\frac{1}{1 + \\exp( -(  \\mathbf x_i  \\mathbf w + b))}\\right)^{y_i} \\left(1- \\frac{1}{1 + \\exp( -(  \\mathbf x_i  \\mathbf w + b))}\\right)^{1-y_i} $$\n",
    "\n",
    "\n",
    "Soit en agrégeant sur la base de données et notant: $exp = \\exp( -(  \\mathbf x_i  \\mathbf w + b))$\n",
    "$$\\mathcal L_{log} = \\sum_i  y_i \\log(\\frac{1}{1+exp}) + (1-y_i) \\log(1-\\frac{1}{1+exp})$$ \n",
    "$$\\mathcal L_{\\log}=\\sum_{i=1}^N \\log(1+exp) ( -y_i -1 + y_i) + \\log(exp)(1-y_i)$$\n",
    "\n",
    "Soit:\n",
    "$$ \\frac{\\partial  }{\\partial w_j} L_{\\log} =\\sum_{i=1}^N x_{ij}( y_i-\\frac{1}{1+exp}) \\in \\mathbb R$$\n",
    "On remarque qu'il est possible de passer à une écriture vectorielle:\n",
    "$$ \\nabla_{\\mathbf w} L_{\\log} =X^T ( Y-\\frac{1}{1+\\exp( -(  \\mathbf X  \\mathbf w + b))}) \\in \\mathbb R^d$$\n",
    "$$ \\frac{\\partial  }{\\partial b} L_{\\log} =\\sum_{i=1}^N ( y_i-\\frac{1}{1+exp}) \\in \\mathbb R$$\n",
    "\n",
    "Note: il est possible de manière **facultative**, comme dans le TME de la semaine dernière, de construire:\n",
    "$$Xe = \\left[\\begin{array}{cc}\n",
    "                \\mathbf x_0 & 1\\\\\n",
    "                \\vdots & \\vdots\\\\\n",
    "                \\mathbf x_N & 1\n",
    "                \\end{array}\n",
    "                \\right] $$\n",
    "On supprime alors les $b$ pour obtenir:\n",
    "$$ \\nabla_{\\mathbf w_e} L_{\\log} =X_e^T ( Y-\\frac{1}{1+\\exp( -(  \\mathbf X_e  \\mathbf w_e))}) \\in \\mathbb R^{d+1}$$\n",
    "\n",
    "### Liste des questions\n",
    "1. Coder la descente de gradient classique (batch) entre deux classes <BR>\n",
    "    Attention, il s'agit d'une montée de gradient pour maximiser la vraisemblance <BR>\n",
    "    Proposition de critère d'arrêt: $\\max_j(|w_{new,j} - w_{old,j}| ) < 10^{-3}$\n",
    "1. Evaluer les performances sur la distinction entre les 2 et les 3\n",
    "1. Passer au multi-classe avec le paradigme un-contre-tous\n",
    "1. [OPT, à faire à la fin] passer à un algorithme de gradient stochastique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence atteinte en 999 itérations\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(X,w):\n",
    "    return 1/(1+np.exp(-(X@w)))\n",
    "\n",
    "def make_mat_lin_biais(X):\n",
    "    N = X.shape[0]\n",
    "    return np.hstack((X,np.ones((N,1))))\n",
    "\n",
    "#1. montée de gradient\n",
    "def rl_gradient_batch(X, Y, epsilon=1e-3, niter_max=1000):\n",
    "    N,d = X.shape\n",
    "    w = np.zeros(d)\n",
    "    old_w = np.zeros(d)\n",
    "    n_batch = niter_max//20\n",
    "    for i in range(niter_max):\n",
    "        rand = np.random.randint(X.shape[0]) - n_batch\n",
    "        batch = X[rand:rand+n_batch]\n",
    "        batch_t = batch.T\n",
    "        batch_y = Y[rand:rand+n_batch]\n",
    "        gradient = epsilon * batch_t @ (batch_y - sigmoid(batch,w))\n",
    "        w += gradient\n",
    "        if i%n_batch == 0:\n",
    "            if np.max(np.abs(w - old_w)) < 1e-3:\n",
    "                break\n",
    "            old_w = w.copy()\n",
    "    print(\"convergence atteinte en\",i,\"itérations\")\n",
    "    return w\n",
    "\n",
    "Xe = make_mat_lin_biais(X)\n",
    "w = rl_gradient_batch(Xe, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille des données : (1389, 256) (1389,)\n",
      "convergence atteinte en 999 itérations\n",
      "App: 0.9928005759539237\n",
      "Test: 0.967032967032967\n"
     ]
    }
   ],
   "source": [
    "# 2. cas sur les classes 2 et 3 & passage à un codage 0/1 pour Y\n",
    "cl1 = 2\n",
    "cl2 = 3\n",
    "X_23 = X[(Y==cl1)|(Y==cl2),:]\n",
    "Y_23 = np.where(Y[(Y==cl1)|(Y==cl2)] == cl1, 1., 0.)\n",
    "Xt_23 = Xt[(Yt==cl1)|(Yt==cl2),:]\n",
    "Yt_23 = np.where(Yt[(Yt==cl1)|(Yt==cl2)] == cl1, 1., 0.)\n",
    "print(\"Taille des données :\",X_23.shape,Y_23.shape)\n",
    "\n",
    "# application de la montée de gradient & evaluation des performances\n",
    "# attention à afficher les Ypred et les Y_23 pour vérifier qu'ils sont comparables\n",
    "# vous pouvez utiliser np.round\n",
    "Xe_23  = make_mat_lin_biais(X_23)\n",
    "Xet_23 = make_mat_lin_biais(Xt_23)\n",
    "\n",
    "w_23  = rl_gradient_batch(Xe_23, Y_23)\n",
    "\n",
    "Y_23_pred  = sigmoid(Xe_23, w_23)\n",
    "Yt_23_pred = sigmoid(Xet_23,w_23)\n",
    "\n",
    "Y_23_pred  = np.where(Y_23_pred >0.5, 1.0, 0.0)\n",
    "Yt_23_pred = np.where(Yt_23_pred>0.5, 1.0, 0.0)\n",
    "\n",
    "print(\"App:\",  np.mean(np.where(Y_23_pred==Y_23, 1.0, 0.0)))\n",
    "print(\"Test:\", np.mean(np.where(Yt_23_pred==Yt_23, 1.0, 0.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sortie attendue\n",
    "```\n",
    "Taille des données : (1389, 256) (1389,)\n",
    "convergence atteinte en  330  itérations # si vous avez fait un print dans le critère d'arret\n",
    "[0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.] \n",
    " [0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
    "App :  0.9992800575953924\n",
    "Test :  0.9615384615384616\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(w[:-1].reshape(16,16))\n",
    "plt.savefig(\"w.png\")\n",
    "# montrer les paramètres des modèles génératifs des classes 2 et 3 pour comparer\n",
    "plt.figure()\n",
    "plt.imshow(w_23[:-1].reshape(16,16))\n",
    "plt.savefig(\"w23.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passage au multiclasse\n",
    "\n",
    "Nous allons utiliser le paradigme *un-contre-tous* mais nous allons le coder proprement dans une fonction.\n",
    "Dans la fonction ```rl_multi(X,Y, epsilon = 1e-3, niter_max=1000)``` effectuer les opérations suivantes:\n",
    "\n",
    "1. Extraire toutes les classes de Y\n",
    "1. Pour chaque classe\n",
    "11. Construire Ycl telle que:\n",
    "$$Y_{cl} = \\left\\{ \n",
    "\\begin{array}{cl}\n",
    "1 & \\mbox{ si } Y == cl     \\\\\n",
    "0 & \\mbox{ sinon (pour toutes les autres classes) }\n",
    "\\end{array}\n",
    "\\right.$$\n",
    "11. Lancer un apprentissage\n",
    "1. Empiler tous les $\\mathbf w$ & $b$ comme suit:\n",
    "\n",
    "$$W = \\left[\\begin{array}{cccc}\n",
    "                \\\\\n",
    "                \\mathbf w_{cl=0} & \\mathbf w_{cl=1} & \\ldots & \\mathbf w_{cl=9}\n",
    "                \\\\ \\\\\n",
    "                \\end{array}\n",
    "                \\right] $$\n",
    "$$\\mathbf b = \\left[\\begin{array}{cccc}\n",
    "                \\mathbf b_{cl=0} & \\mathbf b_{cl=1} & \\ldots & \\mathbf b_{cl=9}\n",
    "                \\end{array}\n",
    "                \\right] $$\n",
    "                \n",
    "On peut alors montrer que:\n",
    "$$ \\frac{1}{1+\\exp( - \\mathbf X W - \\mathbf b)}  = \\left[\\begin{array}{cccc}\n",
    "                p(Y = 1 | X = \\mathbf x_1) & p(Y = 2 | X = \\mathbf x_1) & \\ldots & p(Y = 9 | X = \\mathbf x_1)\n",
    "                \\\\ \n",
    "                \\vdots & &\\ddots & \\vdots\\\\\n",
    "p(Y = 1 | X = \\mathbf x_N) & p(Y = 2 | X = \\mathbf x_N) & \\ldots & p(Y = 9 | X = \\mathbf x_N)\n",
    "\\\\\n",
    "                \\end{array}\n",
    "                \\right] \\in \\mathbb R^{N\\times C}$$\n",
    "               Avec $N$ points et $C$ classes\n",
    "1. Utiliser un ```argmax``` pour extraire le numéro de classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rl_multi(X, Y, epsilon = 1e-3, niter_max=1000):\n",
    "    N,d = X.shape\n",
    "    classes = np.sort(np.unique(Y))\n",
    "    W = np.zeros((len(classes),d))\n",
    "    for c in classes:\n",
    "        W[int(c)] = rl_gradient_batch(X, Y==c)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xe  = make_mat_lin_biais(X)\n",
    "Xet = make_mat_lin_biais(Xt)\n",
    "W = rl_multi(Xe,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perf:\n",
    "Y_pred  = np.argmax(1/(1+np.exp(-Xe@W.T)), axis=1)\n",
    "Yt_pred = np.argmax(1/(1+np.exp(-Xet@W.T)),axis=1)\n",
    "print(Yt[:20],\"\\n\",Yt_pred[:20])\n",
    "\n",
    "pc_good   = np.where(Y_pred == Y , 1., 0.).mean()\n",
    "pc_good_t = np.where(Yt_pred==Yt , 1., 0.).mean()\n",
    "\n",
    "print(\"App : \",pc_good)\n",
    "print(\"Test : \",pc_good_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performances attendues:\n",
    "```\n",
    "App :  0.8824578247154026\n",
    "Test :  0.8166417538614849\n",
    "```\n",
    "Pour l'instant, on ne voit pas encore l'intérêt... Mais ça va venir!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 4: Analyse de l'évolution de la vraisemblance \n",
    "\n",
    "Afin de vérifier le bon fonctionnement de l'algorithme, nous proposons de calculer la vraisemblance au cours des itérations (par exemple, toutes les 10 itérations) et de retourner le résultat pour voir comment se déroule l'apprentissage et pouvoir éventuellement ajuster la valeur de $\\epsilon$.\n",
    "\n",
    "En repartant de:\n",
    "$$\\mathcal L_{log} = \\sum_i  y_i \\log(\\frac{1}{1+exp}) + (1-y_i) \\log(1-\\frac{1}{1+exp})$$ \n",
    "Avec : $exp = \\exp( -(  \\mathbf x_i  \\mathbf w + b))$\n",
    "\n",
    "Modifier la fonction de calcul de la vraisemblance pour retourner l'évolution de la vraisemblance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rl_gradient_batch_L(X, Y, epsilon=1e-3, niter_max=1000):\n",
    "    N,d = X.shape\n",
    "    w = np.zeros(d)\n",
    "    old_w = np.zeros(d)\n",
    "    n_batch = niter_max//20\n",
    "    L = []\n",
    "    for i in range(niter_max):\n",
    "        rand = np.random.randint(X.shape[0]) - n_batch\n",
    "        batch = X[rand:rand+n_batch]\n",
    "        batch_t = batch.T\n",
    "        batch_y = Y[rand:rand+n_batch]\n",
    "        gradient = epsilon * batch_t @ (batch_y - sigmoid(batch,w))\n",
    "        w += gradient\n",
    "        l = -np.sum(Y * np.log(sigmoid(X,w)) + (1 - Y) * np.log(1 - sigmoid(X,w)), axis=0)\n",
    "        L.append(l)\n",
    "        if i%n_batch == 0:\n",
    "            if np.max(np.abs(w - old_w)) < 1e-3:\n",
    "                break\n",
    "            old_w = w.copy()\n",
    "    print(\"convergence atteinte en\",i,\"itérations\")\n",
    "    return w, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cas sur les classes 2 et 3 & passage à un codage 0/1 pour Y\n",
    "cl1 = 2\n",
    "cl2 = 3\n",
    "X_23 = X[(Y==cl1)|(Y==cl2),:]\n",
    "Y_23 = np.where(Y[(Y==cl1)|(Y==cl2)] == cl1, 1., 0.)\n",
    "Xt_23 = Xt[(Yt==cl1)|(Yt==cl2),:]\n",
    "Yt_23 = np.where(Yt[(Yt==cl1)|(Yt==cl2)] == cl1, 1., 0.)\n",
    "print(\"Taille des données :\",X_23.shape,Y_23.shape)\n",
    "\n",
    "w,L = rl_gradient_batch_L(X_23 ,Y_23, epsilon=1e-3)\n",
    "#print(L)\n",
    "print(w.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(L)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 5: Analyse qualitative des solutions\n",
    "\n",
    "Quels sont les pixels qui jouent un role dans la décision?\n",
    "\n",
    "1. Pour une classe de données, je peux déjà afficher l'ampleur des poids $\\mathbf w$ associés à chaque classe. Cela indique si les pixels sont pondérés positivement ou négativement.\n",
    "1. Pour une image donnée, je sais que la décision est de la forme:\n",
    "$$p(y_i=1 | \\mathbf x_i) = \\frac{1}{1 + \\exp( -(  \\mathbf x_i  \\mathbf w + b))}$$\n",
    "Ainsi, la décision est formée d'une addition de $x_{ij}\\cdot w_j$: les plus fortes composante en valeur absolue sont celles qui participent le plus à la décision. <BR>\n",
    "Cette approche est particulièrement intéressante pour analyser les erreurs de classification.\n",
    "Afficher l'image d'un chiffre mal classé et une carte de chaleur indiquant quelles parties de l'image influencent le plus la décision: pour la classe prédite d'une part et pour la classe réelle d'autre part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage des poids des paramètres des 10 classes (PAS DE CODE A AJOUTER)\n",
    "# prérequis: que les w soit en colonnes dans la matrice W\n",
    "plt.figure()\n",
    "plt.subplots(2, 5)\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5,i+1)\n",
    "    plt.imshow(W[i,:-1].reshape(16,16), cmap=\"gray\")\n",
    "    plt.title(\"modèle \"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trouver un échantillon mal classé (PAS DE CODE A AJOUTER):\n",
    "\n",
    "W = W.T\n",
    "W = W[:-1]\n",
    "\n",
    "index = np.where(Y != Y_pred)[0][0] # parmi les points d'apprentissage\n",
    "print(index)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplots(1,3)\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(X[index].reshape(16,16),cmap=\"gray\")\n",
    "plt.title(\"Chiffre\")\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow((X[index]*W[:,int(Y[index])]).reshape(16,16),cmap=\"plasma\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Heatmap cl \"+str(int(Y[index])))\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow((X[index]*W[:,int(Y_pred[index])]).reshape(16,16),cmap=\"plasma\")\n",
    "plt.title(\"Heatmap cl \"+str(int(Y_pred[index])))\n",
    "plt.colorbar()\n",
    "plt.savefig(\"malclasse.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 5-2: limite de la représentation des chiffres\n",
    "\n",
    "L'expérience précédente met en lumière un phénomène évident: seuls les pixels non nuls jouent un role dans la classification.\n",
    "C'est très pénalisant, le fait qu'un pixel soit éteint ne peut influencer la décision que par son inaction... Mais pas forcer le système à aller dans une autre classe.\n",
    "\n",
    "Ce problème est aisément contournable: il suffit de travailler sur $X-1$ (les valeurs de pixels étant entre $0$ et $2$). Les $-1$ qui apparaissent vont alors jouer un role dans la décision.\n",
    "\n",
    "1. Ré-utiliser (sans modification) ```rl_multi``` sur $X-1$\n",
    "1. Calculer les performances en pensant bien à faire l'inférence sur $Xt-1$\n",
    "1. Afficher les contributions des pixels dans cette nouvelle configuration pour une image mal classée\n",
    "\n",
    "Note: avec la régression logistique, les classes $Y$ doivent être dans $\\mathcal Y=\\{0,1\\}$... Mais il n'y a pas de contrainte sur les $X$. Ajouter des descripteurs négatifs n'est pas un problème.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xminus = X-1\n",
    "Xeminus = make_mat_lin_biais(Xminus)\n",
    "\n",
    "Xtminus = Xt-1\n",
    "Xetminus = make_mat_lin_biais(Xtminus)\n",
    "\n",
    "Wm = rl_multi(Xeminus,Y)\n",
    "\n",
    "Y_pred  = np.argmax(1/(1+np.exp(-Xeminus@Wm.T)), axis=1)\n",
    "Yt_pred = np.argmax(1/(1+np.exp(-Xetminus@Wm.T)),axis=1)\n",
    "print(Yt[:20],\"\\n\",Yt_pred[:20])\n",
    "\n",
    "pc_good   = np.where(Y_pred == Y , 1., 0.).mean()\n",
    "pc_good_t = np.where(Yt_pred==Yt , 1., 0.).mean()\n",
    "\n",
    "print(\"App : \",pc_good)\n",
    "print(\"Test : \",pc_good_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sortie attendue:\n",
    "```\n",
    "App :  0.9663969277191058\n",
    "Test :  0.8938714499252616\n",
    "```\n",
    "On commence à voir l'intérêt de la régression logistique !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trouver un échantillon mal classé (PAS DE CODE A AJOUTER):\n",
    "\n",
    "Wm = Wm.T\n",
    "Wm = Wm[:-1]\n",
    "\n",
    "index = np.where(Y != Y_pred)[0][0] # parmi les points d'apprentissage\n",
    "print(index)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplots(1,3)\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(X[index].reshape(16,16),cmap=\"gray\")\n",
    "plt.title(\"Chiffre\")\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(((X[index]-1)*Wm[:,int(Y[index])]).reshape(16,16),cmap=\"plasma\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Heatmap cl \"+str(int(Y[index])))\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(((X[index]-1)*Wm[:,int(Y_pred[index])]).reshape(16,16),cmap=\"plasma\")\n",
    "plt.title(\"Heatmap cl \"+str(int(Y_pred[index])))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 6: Régularisation, performance & interprétation\n",
    "\n",
    "Dans ce problème en assez grande dimension (256), nous voyons un peu de sur-apprentissage: les performances sont meilleures en apprentissage qu'en test.\n",
    "\n",
    "On fait souvent l'hypothèse que ce phénomène est lié à un estimateur trop complexe. Afin de simplifier la fonction de coût, on proposer de régulariser le problème d'apprentissage qui devient:\n",
    "\n",
    "$$\\arg\\max_\\theta  \\mathcal L - \\lambda \\Omega(\\theta), \\qquad \\mbox{avec: } \\Omega(\\theta) = \\left\\{\\begin{array}{cl}\n",
    "\\sum_j \\theta_j^2 & \\mbox{ régularisation } L_2 \\\\\n",
    "\\sum_j |\\theta_j| & \\mbox{ régularisation } L_1 \\\\\n",
    "\\end{array}\n",
    "\\right.$$\n",
    "\n",
    "$\\lambda$ doit être choisi soigneusement sous peine d'aboutir à une solution dégénée (ou non modifiée). La régularisation $L_2$ est plus stable est facile à exploiter, la régularisation $L_1$ est plus complexe et moins stable mais elle permet d'annuler complètement les poids attribués à certains pixels. En effet, dans l'implémentation, nous allons traiter la fonction $\\Omega$ à part de la vraisemblance:\n",
    "Toutes les itérations, nous allons mettre à jour:\n",
    "\n",
    "$$\\mathbf w \\leftarrow \\mathbf w - \\lambda \\left\\{\\begin{array}{cl}\n",
    "\\nabla_{\\mathbf w,b} \\Omega(\\mathbf w,b) = 2\\mathbf w, 2b  & \\mbox{ régularisation } L_2 \\\\\n",
    "\\nabla_{\\mathbf w,b} \\Omega(\\mathbf w,b) = sign(\\mathbf w),sign(b) & \\mbox{ régularisation } L_1 \\\\\n",
    "\\end{array}\n",
    "\\right. $$\n",
    "\n",
    "En interprétant la formule ci-dessus, on se rend compte que ça ramène systématiquement les poids du modèle vers 0: l'idée est donc bien de simplifier le modèle... Seuls les dimensions vraiment intéressantes seront pondérées.\n",
    "\n",
    "**Note:** Par défaut, il n'est pas évident d'améliorer les performances avec la régularisation sur ce problème... C'est néanmoins une procédure très efficace sur la plupart des jeux de données.\n",
    "\n",
    "**Note2:** Les expériences étant un peu chères en temps de calcul, pensez à réduire niter_max pendant le debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rl_gradient_batch_reg(X, Y, epsilon=1e-3, niter_max=1000, lam=1e-5, conv=True):\n",
    "    N,d = X.shape\n",
    "    w = np.zeros(d)\n",
    "    old_w = np.zeros(d)\n",
    "    n_batch = niter_max//20\n",
    "    for i in range(niter_max):\n",
    "        rand = np.random.randint(X.shape[0]) - n_batch\n",
    "        batch = X[rand:rand+n_batch]\n",
    "        batch_t = batch.T\n",
    "        batch_y = Y[rand:rand+n_batch]\n",
    "        gradient = epsilon * batch_t @ (batch_y - sigmoid(batch,w))\n",
    "        w = w + (gradient - lam*w*2)\n",
    "        if i%n_batch == 0 and conv:\n",
    "            if np.max(np.abs(w - old_w)) < 1e-3:\n",
    "                break\n",
    "        old_w = w.copy()\n",
    "    print(\"convergence atteinte en\",i,\"itérations\")\n",
    "    return w\n",
    "\n",
    "# Soit vous passez des fonctions en arguments, soit il faut redéfinir une nouvelle version de rl_multi\n",
    "# dans le cadre du TP, on prend la seconde option: plus simple mais plus moche\n",
    "def rl_multi_reg(X, Y, epsilon = 1e-3, niter_max=1000, lam=1e-5, conv=True):\n",
    "    N,d = X.shape\n",
    "    classes = np.sort(np.unique(Y))\n",
    "    W = np.zeros((len(classes),d))\n",
    "    for c in classes:\n",
    "        W[int(c)] = rl_gradient_batch_reg(X, Y==c, niter_max=niter_max, lam=lam, conv=conv)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation des performances\n",
    "Xminus = X-1\n",
    "Xeminus = make_mat_lin_biais(Xminus)\n",
    "\n",
    "Xtminus = Xt-1\n",
    "Xetminus = make_mat_lin_biais(Xtminus)\n",
    "\n",
    "Wm = rl_multi_reg(Xeminus,Y)\n",
    "\n",
    "Y_pred  = np.argmax(1/(1+np.exp(-Xeminus@Wm.T)) ,axis=1)\n",
    "Yt_pred = np.argmax(1/(1+np.exp(-Xetminus@Wm.T)),axis=1)\n",
    "print(Yt[:20],\"\\n\",Yt_pred[:20])\n",
    "\n",
    "pc_good   = np.where(Y_pred == Y , 1., 0.).mean()\n",
    "pc_good_t = np.where(Yt_pred==Yt , 1., 0.).mean()\n",
    "\n",
    "print(\"App : \",pc_good)\n",
    "print(\"Test : \",pc_good_t)"
   ]
  },
  {
   "attachments": {
    "CurseDim.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 6: Malédiction de la dimensionnalité\n",
    "\n",
    "Nous vous proposons ici de modifier les données pour ajouter des colonnes de bruit. Montrer que la performances se réduit lorsque l'on augmente le nombre de dimensions fantomes.\n",
    "\n",
    "- la fonction d'ajout des données fantomes est fournie\n",
    "- faites la boucle avec des ajouts de $[0,100,150,200,250]$ colonnes et tracer l'évolution des performances en apprentissage et en test.\n",
    "    - Attention: il faut donc modifier $X$ et $Xt$ avec le même nombre de colonne fantome\n",
    "    \n",
    "**Note:** les expériences sont couteuses, encore une fois, limitez niter_max ou faites les calculs sur un serveur distant (3 minutes en limitant à 300 itérations)... <BR>\n",
    "Attention, le fait de limiter les itérations est une forme de régularisation (appelée *early stopping*): s'il n'y a pas assez d'itération, on ne voit pas les effets pervers de la dimensionnalité des données!\n",
    "\n",
    "**Note 2:** Evidemment, c'est dans ce cas de figure -qui correspond à beaucoup d'applications réelles- que la régularisation va aider.\n",
    "\n",
    "Avec 300 itérations, vous obtenez:<br>\n",
    "![CurseDim.png](attachment:CurseDim.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ajoute du bruit (et on enlève 1) \n",
    "# ATTENTION : ne pas enlever une seconde fois 1 ensuite !\n",
    "def ajout_colonne_randn(X,d, sig = 1.):\n",
    "    return np.hstack((X-1, np.random.randn(len(X),d)*sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnoise    = np.array([0,100,150,200,250,300,350,400,450,500])\n",
    "perf_app  = np.zeros(len(dnoise))\n",
    "perf_test = np.zeros(len(dnoise))\n",
    "\n",
    "Xminus = X-1\n",
    "Xeminus = make_mat_lin_biais(Xminus)\n",
    "Xtminus = Xt-1\n",
    "Xetminus = make_mat_lin_biais(Xtminus)\n",
    "\n",
    "for i,d in enumerate(dnoise):\n",
    "    Xeminus_tmp  = ajout_colonne_randn(Xeminus, d)\n",
    "    Xetminus_tmp = ajout_colonne_randn(Xetminus, d)\n",
    "    Wm = rl_multi_reg(Xeminus_tmp, Y, niter_max=1000, conv=False)\n",
    "    Y_pred  = np.argmax(1/(1+np.exp(-Xeminus_tmp@Wm.T)) ,axis=1)\n",
    "    Yt_pred = np.argmax(1/(1+np.exp(-Xetminus_tmp@Wm.T)),axis=1)\n",
    "    perf_app[i]   = np.where(Y_pred == Y , 1., 0.).mean()\n",
    "    perf_test[i]  = np.where(Yt_pred==Yt , 1., 0.).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(dnoise,perf_app, 'r')\n",
    "plt.plot(dnoise,perf_test, 'b')\n",
    "plt.legend(['App','Test'])\n",
    "plt.grid()\n",
    "plt.savefig('CurseDim.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 7: et par rapport aux méthodes discriminantes à base de fonctions de cout?\n",
    "\n",
    "Tester l'algorithme du perceptron vu en cours, avec l'astuce du un-contre-tous pour le passage au multi-classes.\n",
    "Attention, pour le perceptron, le codage des deux classes est en $\\{-1, 1\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) # Pour comparer l'acc avec les gradients stochastiques\n",
    "\n",
    "def descente_grad(X, Y, c, eps=1e-3, niter_max=10_000):\n",
    "    w = np.zeros(X.shape[1]) \n",
    "    for _ in range(niter_max):\n",
    "        rand = np.random.randint(X.shape[0])\n",
    "        if np.dot(w,X[rand]) * Y[rand] <= 0 : # Check si bien classe\n",
    "            gradient = eps * (Y[rand] * X[rand]) \n",
    "            w = w + gradient # MAJ du gradient\n",
    "    return w\n",
    "\n",
    "def multi_grad_stoch(X, Y, eps=1e-3, niter_max=10_000):\n",
    "    N,d = X.shape\n",
    "    classes = np.sort(np.unique(Y))\n",
    "    W = np.zeros((len(classes),d))\n",
    "    for c in range(len(classes)):\n",
    "        Y_tmp = np.where(Y==c, 1.0, -1.0) # 1 contre tous\n",
    "        W[int(c)] = descente_grad(X, Y_tmp, c, eps, niter_max)\n",
    "    return W\n",
    "\n",
    "def predict(X, W):\n",
    "    return np.argmax(X@W.T,axis=1)\n",
    "\n",
    "def get_acc(Yt, Yt_pred):\n",
    "    return np.where(Yt_pred==Yt , 1., 0.).mean()\n",
    "    \n",
    "def perceptron(X, Xt, Y, Yt, eps=1e-3, niter_max=10_000):\n",
    "    W = multi_grad_stoch(X, Y, eps, niter_max)\n",
    "    Yt_pred = predict(Xt, W)\n",
    "    acc = get_acc(Yt, Yt_pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron(Xeminus, Xetminus, Y, Yt, niter_max=100_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice supplementaire : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient avec Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descente_grad(X, Y, c, eps=1e-3, niter_max=10_000):\n",
    "    w = np.zeros(X.shape[1]) \n",
    "    value = w\n",
    "    gamma = 0.95\n",
    "    for _ in range(niter_max):\n",
    "        rand = np.random.randint(X.shape[0])\n",
    "        if np.dot(w,X[rand]) * Y[rand] <= 0 :\n",
    "            gradient = eps * (Y[rand] * X[rand]) \n",
    "            new_value = (1-gamma) * gradient + gamma * value\n",
    "            w = w + new_value \n",
    "            value = new_value\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "perceptron(Xeminus, Xetminus, Y, Yt, niter_max=100_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec un critere de rejet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W, confidence):\n",
    "    pred = X@W.T\n",
    "    index_to_delete = []\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i].max() < confidence:\n",
    "            index_to_delete.append(i)\n",
    "    return np.argmax(X@W.T,axis=1), index_to_delete\n",
    "\n",
    "def get_acc(Yt, Yt_pred, index_to_delete):\n",
    "    Yt = np.delete(Yt, index_to_delete, 0)\n",
    "    Yt_pred = np.delete(Yt_pred, index_to_delete, 0)\n",
    "    return np.where(Yt_pred==Yt , 1., 0.).mean()\n",
    "\n",
    "def perceptron(X, Xt, Y, Yt, confidence, eps=1e-3, niter_max=10_000):\n",
    "    W = multi_grad_stoch(X, Y, eps, niter_max)\n",
    "    Yt_pred, index_to_delete = predict(Xt, W, confidence)\n",
    "    acc = get_acc(Yt, Yt_pred, index_to_delete)\n",
    "    return acc, len(index_to_delete)/len(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "confidence = 0.5\n",
    "acc, lost = perceptron(Xeminus, Xetminus, Y, Yt, confidence, niter_max=100_000)\n",
    "print(acc) # On peut monter a 100% accuracy\n",
    "print((1-lost)*100) # mais en gardant seulement 5% des valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "confidence = 0.3\n",
    "acc, lost = perceptron(Xeminus, Xetminus, Y, Yt, confidence, niter_max=100_000)\n",
    "print(acc) # On peut monter a 98% accuracy\n",
    "print((1-lost)*100) # mais en gardant seulement 34% des valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "confidence = 0.1\n",
    "acc, lost = perceptron(Xeminus, Xetminus, Y, Yt, confidence, niter_max=100_000)\n",
    "print(acc) # On peut monter a 96% accuracy\n",
    "print((1-lost)*100) # en gardant seulement 74% des valeurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec deux criteres de rejet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W, confidence):\n",
    "    pred = X@W.T\n",
    "    index_to_delete = []\n",
    "    for i in range(len(pred)):\n",
    "        sort = np.sort(pred[i])\n",
    "        if sort[-1] < confidence or (sort[-1] > confidence and sort[-2] > confidence):\n",
    "            index_to_delete.append(i)\n",
    "    return np.argmax(X@W.T,axis=1), index_to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "confidence = 0.50\n",
    "acc, lost = perceptron(Xeminus, Xetminus, Y, Yt, confidence, niter_max=100_000)\n",
    "print(acc) # On peut monter a 100% accuracy\n",
    "print((1-lost)*100) # mais en gardant seulement 5% des valeurs\n",
    "# Ici par de grandes differences entre un et deux critere de rejet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation entre critere d'arret et accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidences = np.arange(0,0.5,0.05)\n",
    "n = len(confidences)\n",
    "accs = np.zeros(n)\n",
    "losses = np.zeros(n)\n",
    "for i in range(n):\n",
    "    acc, lost = perceptron(Xeminus, Xetminus, Y, Yt, confidences[i], niter_max=100_000)\n",
    "    accs[i] = acc\n",
    "    losses[i] = lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accs) # On peut voir qu'il est tres cher d'ameliorer son accuracy\n",
    "plt.plot(losses) # car on perd beaucoup de valeurs pour peu de pourcentage gagne.\n",
    "plt.legend((\"Accuracy\",\"% Data lost\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des cas difficiles a discriminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(X, Xt, Y, Yt, confidence, eps=1e-3, niter_max=10_000):\n",
    "    W = multi_grad_stoch(X, Y, eps, niter_max)\n",
    "    Yt_pred, index_to_delete = predict(Xt, W, confidence)\n",
    "    acc = get_acc(Yt, Yt_pred, index_to_delete)\n",
    "    return acc, index_to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "confidence = 0.1\n",
    "acc, idx = perceptron(Xeminus, Xetminus, Y, Yt, confidence, niter_max=100_000)\n",
    "hard = Xt[idx]\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in hard[:3]:\n",
    "    plt.imshow(img.reshape(16,16))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
