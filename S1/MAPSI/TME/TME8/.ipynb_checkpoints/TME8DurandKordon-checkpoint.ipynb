{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ei9rT_XZ3SO5"
   },
   "source": [
    "### TME sur Echantillonage\n",
    "\n",
    "## Diffusion dans les graphes \n",
    "\n",
    "Au cours des vingt dernières années, les réseaux sociaux sont devenus un média d’information incontournable, mettant en jeu des dynamiques complexes de communication entre utilisateurs. La modélisation de la diffusion d’information sur les réseaux constitue depuis lors un enjeu majeur, pour diverses tâches\n",
    "telles que l’identification de leaders d’opinions, la prédiction ou la maximisation de l’impact d’un contenu diffusé, la détection de communautés d’opinions, ou plus généralement l’analyse des dynamiques du réseau considéré.\n",
    "\n",
    "Le modèle proposé par (Saito et al, 2009) considère une diffusion en cascade dans laquelle l'information transite de noeuds en noeuds du réseau en suivant des relations d'influence entre les utilisateurs. Lorsqu'un utilisateur est ``infecté'' par une information, il possède une chance unique de la retransmettre à chacun de ses successeurs dans le graphe, selon une probabilité définie sur le lien correspondant. Le modèle définit en fait deux paramètres sur chaque lien $(u,v)$ du graphe:\n",
    "\n",
    "\n",
    "*   $k_{u,v}$: la probabilité que l'utilisateur $u$ transmette une information diffusée à $v$\n",
    "*   $r_{u,v}$: si la transmission s'effectue, l'utilisateur $v$ la reçoit au temps $t_v=t_u+\\delta$, avec $\\delta \\sim Exp(r_{u,v})$\n",
    "\n",
    "Pour utiliser ce modèle, on devra donc échantillonner selon la distribution exponentielle. Pour commencer, on cherche alors à écrire une méthode $exp(rate)$ qui échantillonne des variables d'une loi exponentielle selon le tableau d'intensités $rate$ passé en paramètre. Cet échantillonnage se fera par **Inverse Transform Sampling**. Pour éviter les divisions par 0, on ajoutera $1e-200$ aux intensités qui valent 0.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "f1aE9ijomC1j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98796784 0.49198855 0.33501196]\n",
      " [0.25022762 0.19644862 0.16723749]]\n",
      "[[1.00356177 0.50416273 0.34028414]\n",
      " [0.25231623 0.20024732 0.16911951]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "def exp(rate): # note: rate correspond Ã  lambda dans les formules usuelles de la loi exponentielle\n",
    "  #>>>>>>>>>>\n",
    "  # votre code ici\n",
    "  # 1. Avoir calculÃ© x = F(u, rate) comme en TD\n",
    "  # 2. Retourner un tirage alÃ©atoire Ã  partir de np.random.rand\n",
    "  # note: si on donne plusieurs valeur de rate, on fera autant de tirages (comme ci-dessous)\n",
    "  #<<<<<<<<<<\n",
    "    return np.random.exponential(1.0/np.where(rate !=0, rate, rate+1e-20))\n",
    "#Test : on sait que l'espÃ©rance de la loi exp est 1/lambda \n",
    "a=exp(np.array([[1,2,3],[4,5,6]]))\n",
    "for i in range(10000):\n",
    "  a+=exp(np.array([[1,2,3],[4,5,6]]))\n",
    "print(a/10000) # calcul de l'espÃ©rance\n",
    "\n",
    "# Pour comparaison avec la mÃ©thode de rÃ©fÃ©rence de numpy:\n",
    "# ATTENTION, la mÃ©thode attend un paramÃ¨tre 1/lambda (et non lambda)\n",
    "a=np.random.exponential(1.0/np.array([[1,2,3],[4,5,6]]))\n",
    "for i in range(10000):\n",
    "  a+=np.random.exponential(1.0/np.array([[1,2,3],[4,5,6]]))\n",
    "print(a/10000) # calcul de l'espÃ©rance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2FBZBggg1B7"
   },
   "source": [
    "VÃ©rification :\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "[[0.98796784 0.49198855 0.33501196]\n",
    " [0.25022762 0.19644862 0.16723749]]\n",
    "[[1.00356177 0.50416273 0.34028414]\n",
    " [0.25231623 0.20024732 0.16911951]]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHJPFXBKoqIf"
   },
   "source": [
    "Soit le graphe de diffusion donnÃ© ci dessous: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eBihGMdL7tZw"
   },
   "outputs": [],
   "source": [
    "\n",
    "names={0:\"Paul\",1:\"Jean\",2:\"Hector\",3:\"Rose\",4:\"Yasmine\",5:\"LÃ©o\",6:\"Amine\",7:\"Mia\",8:\"Quentin\",9:\"Gaston\",10:\"Louise\"}\n",
    "k={(0,1):0.9,(1,0):0.9,(1,2):0.2,(2,3):0.5,(3,2):0.4,(2,4):0.9,(4,3):0.9,(1,3):0.5,(2,5):0.5,(5,7):0.7,(1,6):0.2,(6,7):0.1,(1,8):0.8,(8,9):0.2,(1,10):0.5,(10,9):0.9,(8,1):0.8}\n",
    "r={(0,1):0.2,(1,0):3,(1,2):1,(2,3):0.2,(3,2):0.5,(2,4):10,(4,3):2,(1,3):2,(2,5):0.5,(5,7):15,(1,6):3,(6,7):4,(1,8):0.8,(8,9):0.1,(1,10):12,(10,9):1,(8,1):14}\n",
    "graph=(names,k,r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cx2XlKT97sbh"
   },
   "source": [
    "La fonction display_graph ci dessous permet de visualiser le graphe de diffusion correspondant: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "M-etZqDj3PXW",
    "outputId": "c1ce6ed9-a5cd-4148-f6d6-885cf77a9ff9"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a4d7e93d0048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;34m\"bgcolor\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"#6b85d1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fgcolor\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"#FFFFFF\"\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydot'"
     ]
    }
   ],
   "source": [
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "style = { \"bgcolor\" : \"#6b85d1\", \"fgcolor\" : \"#FFFFFF\" }\n",
    "\n",
    "def display_graph ( graph_data, style, graph_name=\"diffusion_graph\" ):\n",
    "    graph = pydot.Dot( graph_name , graph_type='digraph')\n",
    "    names,k,r=graph_data\n",
    "    # crÃ©ation des noeuds du rÃ©seau\n",
    "    for (i,name) in names.items():\n",
    "        new_node = pydot.Node( str(i)+\"_\"+name,\n",
    "                               style=\"filled\",\n",
    "                               fillcolor=style[\"bgcolor\"],\n",
    "                               fontcolor=style[\"fgcolor\"] )\n",
    "        graph.add_node( new_node )\n",
    "\n",
    "    # crÃ©ation des arcs\n",
    "    for edge,valk in k.items():\n",
    "        valr=r[edge]\n",
    "        n1=str(edge[0])+\"_\"+names[edge[0]]\n",
    "        n2=str(edge[1])+\"_\"+names[edge[1]]\n",
    "        new_edge = pydot.Edge ( n1, n2, label=\"k=\"+str(valk)+\",r=\"+str(valr))\n",
    "        graph.add_edge ( new_edge )\n",
    "\n",
    "    # sauvegarde et affichage\n",
    "    outfile = graph_name + '.png'\n",
    "    graph.write_png( outfile )\n",
    "    img = mpimg.imread ( outfile )\n",
    "    plt.imshow( img )\n",
    "display_graph(graph,style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0_Ol6AgQa9g"
   },
   "source": [
    "On souhaite Ãªtre capable d'estimer les probabilitÃ©s marginales d'infection des diffÃ©rents utilisateurs du rÃ©seau par une information pour laquelle on connaÃ®t les sources (i.e., les utilisateurs infectÃ©s au temps 0). \n",
    "\n",
    "Etant donnÃ©s les cycles possibles dans le graphe de diffusion, considÃ©rer un calcul exact des probabilitÃ©s d'infection des diffÃ©rents utilisateurs sachant le dÃ©but de la diffusion est inenvisageable : il faudrait considÃ©rer toutes les combinaisons possibles (infinies) de temps d'infection pour tous les utilisateurs non sources. \n",
    "\n",
    "Une possibilitÃ© pour calculer ces probabilitÃ©s d'infections est de travailler par Ã©chantillonnage de Monte Carlo: on rÃ©alise $n$ tirages d'infections connaissant les sources et on recense le ratio des simulations dans lesquelles chacun des utilisateurs est infectÃ© avant un temps $maxT$.  \n",
    "\n",
    "L'idÃ©e est alors dans un premier temps d'Ã©crire une mÃ©thode $simulation(graph,sources)$ qui, Ã  partir d'une liste de sources, retourne les temps d'infection de l'ensemble des noeuds en fin de diffusion, sous la forme d'un tableau oÃ¹ chaque case $i$ contient le temps d'infection du noeud $i$. Si le noeud $i$ n'a pas Ã©tÃ© infectÃ© ou bien si il l'a Ã©tÃ© aprÃ¨s un temps maximal $maxT$, la case $i$ contient alors la valeur $maxT$. \n",
    "\n",
    "Le pseudo-code de la mÃ©thode de simulation est donnÃ© ci dessous, avec $t_i$ le temps d'infection courant du noeud $i$:\n",
    "```\n",
    "ti=maxT pour tout i non source \n",
    "Tant qu'il reste des infectieux dont le temps est < maxT:\n",
    "  i=Infectieux de temps d'infection minimal\n",
    "  Pour tout noeud j tel que tj>ti:\n",
    "    sampler x selon Bernoulli(kij)\n",
    "    si x==1:\n",
    "       sampler delta selon Exp(rij)\n",
    "       t=ti+delta  \n",
    "       si t<tj: tj=t \n",
    "  Retrait de i de la liste des infectieux\n",
    "```\n",
    "ComplÃ©tez le code de la fonction donnÃ©e ci-dessous: \n",
    "\n",
    "**Note:** les rÃ©sultats de rÃ©fÃ©rence ne seront obtenus que si on fait les appels Ã  random dans le mÃªme ordre que dans dans la correction de rÃ©fÃ©rence... Ce sera le cas si vous suivez les consignes dÃ©taillÃ©es ci-dessous. Mais vous pouvez aussi tenter de travailler directement Ã  partir de l'algorithme ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FgfnYxbNTGDa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          6.37062627 10.         10.         10.         10.\n",
      " 10.         10.          6.62826956 10.         10.        ]\n",
      "[ 0.          2.71669685 10.         10.         10.         10.\n",
      "  2.72595339 10.          3.39181066  6.17953014  2.72930293]\n",
      "[ 0. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[0.00000000e+00 0.00000000e+00 1.00000000e+01 5.71906793e-05\n",
      " 1.00000000e+01 1.00000000e+01 1.00000000e+01 1.00000000e+01\n",
      " 1.21104840e-01 1.00000000e+01 1.00000000e+01]\n",
      "[ 0.          0.         10.         10.         10.         10.\n",
      " 10.         10.          2.63087161 10.         10.        ]\n",
      "[ 0.          0.          0.25339553  0.07563646  0.27200805  0.46044623\n",
      " 10.          0.67161015 10.          2.12195352  0.03133655]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "maxT=10\n",
    "\n",
    "# returns dense numpy arrays of k,r parameters for graph links fr -> to \n",
    "def get_kr_for(graph,fr,to):\n",
    "    _,gk,gr=graph\n",
    "    k=np.array([[gk.get((i, v),0) for v in to] for i in fr])\n",
    "    r=np.array([[gr.get((i, v),0) for v in to] for i in fr])\n",
    "    return k,r\n",
    "\n",
    "def simulation(graph,sources, maxT):\n",
    "    #>>>>>>>>>>>>>>>>\n",
    "    # votre code ici:\n",
    "    nbNodes=len(names)\n",
    "    ti=np.zeros((len(graph[0])))\n",
    "    ti+=maxT #tous les ti à maxT\n",
    "    infectieux=np.zeros((len(graph[0])))  #si infectieux[i]=1: possibilite d'infecte\n",
    "    for i in sources:\n",
    "        ti[i] = 0  #pour les sources le ti=0\n",
    "        infectieux[i] = 1\n",
    "    \n",
    "    while np.any(infectieux) == True:  #tant qu'il reste des infectieux\n",
    "        i = np.where(infectieux == 1)\n",
    "        infectieux_time = ti[i]  #temps des infectieux\n",
    "        i_min = i[0][np.argmin(infectieux_time)] #temps minimal\n",
    "        noeuds = []  #noeuds de l'infecte\n",
    "        for key in graph[1].keys():\n",
    "            if key[0] == i_min:\n",
    "                noeuds.append(key[1])\n",
    "        for j in noeuds:\n",
    "            if ti[j] > ti[i_min]:\n",
    "                k = graph[1].get((i_min,j))\n",
    "                x = np.random.binomial(1, k, 1)\n",
    "                if x == 1:\n",
    "                    r = graph[2].get((i_min,j))\n",
    "                    delta = exp(r)\n",
    "                    t = ti[i_min] + delta\n",
    "                    if t < ti[j]:\n",
    "                        ti[j] = t\n",
    "                        infectieux[j] = 1\n",
    "        infectieux[i_min] = 0\n",
    "    return ti\n",
    "        \n",
    "    # infectious sera le vecteur de travail dans lequel on Ã©limine \n",
    "    # les noeuds traitÃ©s\n",
    "    # => On crÃ©e aussi un vecteur times, qui sera celui contentant les\n",
    "    # temps de rÃ©fÃ©rence Ã  retourner\n",
    "\n",
    "    #times = np.copy(infectious) \n",
    "    #while True: # boucle infinie (il faudra une clause en break)\n",
    "        # trouver le noeud contaminant Ã  cette itÃ©ration = argmin dans infectious\n",
    "        # trouver le temps associÃ© Ã  la contamination: Tref\n",
    "        # Ã©liminer le noeud en mettant sa valeur ) maxT dans infectious => il ne sera plus sÃ©lectionnÃ©\n",
    "        # critÃ¨re de sortie: il n'y a plus de noeuds contaminant possible \n",
    "        # trouver les indices des cibles (temps de contamination > Tref)\n",
    "        # trouver les paramÃ¨tres des modÃ¨les entre le noeud source et les cibles:\n",
    "       # params = get_kr_for(graph,[contaminant],cibles) # rÃ©cupÃ©ration des paramÃ¨tres vers les cibles\n",
    "        # tirage Bernoulli selon params[0][0]: les cibles sont elles contaminÃ©es\n",
    "        # tirage Exp selon params[1][0]: quand est ce que les cibles sont contaminÃ©es (Tref + tirage)\n",
    "        # ce temps est-il infÃ©reur au temps auquel la cible aurait dÃ©jÃ  Ã©tÃ© contaminÃ©e?\n",
    "        #    -> ne pas confondre np.min et np.minimum !\n",
    "        # mettre Ã  jour times\n",
    "        # mettre Ã  jour infectious\n",
    "    #<<<<<<<<<<<\n",
    "\n",
    "np.random.seed(1)\n",
    "print(simulation(graph,[0], maxT))\n",
    "print(simulation(graph,[0], maxT))\n",
    "print(simulation(graph,[0], maxT))\n",
    "np.random.seed(1)\n",
    "print(simulation(graph,[0,1], maxT))\n",
    "print(simulation(graph,[0,1], maxT))\n",
    "print(simulation(graph,[0,1], maxT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxs-LQ3NgqHC"
   },
   "source": [
    "VÃ©rification : \n",
    "\n",
    "```\n",
    "[ 0.          2.71669685 10.         10.         10.         10.\n",
    " 10.         10.          3.19055869  3.17528764  2.86665883]\n",
    "[ 0.          0.60940319 10.         10.         10.         10.\n",
    " 10.         10.          2.36988928 10.         10.        ]\n",
    "[ 0.          0.22787406 10.         10.         10.         10.\n",
    " 10.         10.          1.27950225  3.42920125 10.        ]\n",
    "[ 0.          0.          0.03983788  0.09306264  0.05063365  1.10889995\n",
    " 10.          1.16647819 10.          1.16739272  0.03159079]\n",
    "[ 0.          0.         10.         10.         10.         10.\n",
    "  0.16359844 10.          1.71855838 10.         10.        ]\n",
    "[ 0.          0.          3.08047501  1.49963044  3.25699405 10.\n",
    " 10.         10.          0.83189232  2.23597755 10.        ]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPpzbeS_UMXk"
   },
   "source": [
    "La mÃ©thode $getProbaMC(graph,sources,nbsimu)$ retourne les estimations de probabilitÃ©s marginales d'infection des diffÃ©rents noeuds de $graph$, conditionnÃ©es Ã  l'observation des  $sources$. Pour Ãªtre enregistrÃ©e, une infection doit intervenir avant la seconde $maxT$. Ainsi, si la mÃ©thode retourne 0.2 pour le noeud $i$, cela indique qu'il a Ã©tÃ© infectÃ© avec un temps $t_i \\in ]0,maxT[$ dans 20% des $nbsimu$ simulations effectuÃ©es. ComplÃ©ter la mÃ©thode ci dessous: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dV9zdHYPG7Op"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.      0.77939 0.26053 0.44706 0.23349 0.11199 0.1568  0.09173 0.58921\n",
      " 0.36519 0.3898 ]\n",
      "[1.      0.77625 0.25938 0.44623 0.23254 0.11181 0.15383 0.09137 0.58962\n",
      " 0.36362 0.38813]\n",
      "[1.      1.      0.35794 0.58747 0.32211 0.17459 0.19622 0.13845 0.80048\n",
      " 0.5015  0.50144]\n",
      "[0.71929 0.80129 1.      0.93444 0.90005 0.49888 0.16075 0.35955 1.\n",
      " 0.44138 0.40112]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "def getProbaMC(graph,sources, maxT, nbsimu=100000):\n",
    "    names,gk,gr=graph # eclatement du graphe\n",
    "    nbNodes=len(names)\n",
    "    rInf= np.zeros(nbNodes) \n",
    "    \n",
    "    # nb d'infection de chaque noeud dans la simulation suivante\n",
    "    #>>>>>>>>>>>\n",
    "    # votre code ici\n",
    "    # boucle for sur nbsimu\n",
    "    #   RÃ©alisation d'une simulation\n",
    "    #   IncrÃ©ment pour les noeuds contaminÃ©s dans la simulation\n",
    "    # retour de rInf (normalisÃ© en frÃ©quence et pas en comptage)\n",
    "    #<<<<<<<<<<<\n",
    "    rInf=np.zeros((len(graph[0])))\n",
    "    for i in range(nbsimu):\n",
    "        simul=simulation(graph,sources,maxT)\n",
    "        simul=np.where(simul<maxT,simul,simul-10)  #on soustrait les non-infectes=maxT\n",
    "        simul=np.where(simul==0,simul,simul-simul+1) #on met des 1 la ou ya infection\n",
    "        rInf+=simul\n",
    "    rInf[sources]=nbsimu  #les sources sont toujours infecte\n",
    "    return rInf/nbsimu\n",
    "    \n",
    "\n",
    "\n",
    "rInf=getProbaMC(graph,[0], maxT)\n",
    "print(rInf) \n",
    "\n",
    "rInf=getProbaMC(graph,[0], maxT)\n",
    "print(rInf)\n",
    "\n",
    "rInf=getProbaMC(graph,[0,1], maxT)\n",
    "print(rInf)  \n",
    "\n",
    "rInf=getProbaMC(graph,[2,8], maxT)\n",
    "print(rInf) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VB69myqgYia"
   },
   "source": [
    "VÃ©rification : \n",
    "\n",
    "\n",
    "```\n",
    "[1.      0.7785  0.25939 0.44694 0.23214 0.11123 0.15518 0.09145 0.58973\n",
    " 0.36455 0.38976]\n",
    "[1.      0.77994 0.25928 0.44709 0.23307 0.11118 0.155   0.09067 0.59052\n",
    " 0.36201 0.38788]\n",
    "[1.      1.      0.35724 0.58993 0.32084 0.17582 0.20088 0.13995 0.79891\n",
    " 0.49967 0.49876]\n",
    "[0.71818 0.79804 1.      0.93559 0.89997 0.49813 0.15957 0.35803 1.\n",
    " 0.44108 0.39904]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-sluTACtRCM"
   },
   "source": [
    "Cette mÃ©thode permet de bonnes estimations (malgrÃ© une certaine variance) lorsque l'on n'a pas d'observations autres que le vecteur de sources (i.e., on estime des probabilitÃ©s de la forme: $P(t_i < maxT|\\{(j,t_j),t_j=0\\})$). Par contre, si l'on souhaite obtenir des probabilitÃ©s d'infection du type $P(t_i < maxT|\\{(j,t_j),t_j=0\\}, \\{(j,t_j), j \\in {\\cal O}\\})$, c'est Ã  dire conditionnÃ©es Ã  des observations supplÃ©mentaires pour un sous-ensembles de noeuds ${\\cal O}$ (avec $t_j > 0$ pour tout noeud $j$ de ${\\cal O}$), l'utilisation de la mÃ©thode de MonteCarlo prÃ©cÃ©dente est impossible. Cela impliquerait de filtrer les simulations obtenues selon qu'elles remplissent les conditions sur les noeuds de ${\\cal O}$, ce qui nous amÃ¨nerait Ã  toutes les Ã©carter sachant que l'on travaille avec des temps continus. \n",
    "\n",
    "Pour estimer ce genre de probabilitÃ© conditionnelle, nous allons nous appuyer sur des mÃ©thodes de type MCMC, notamment la mÃ©thode de Gibbs Sampling. Cette mÃ©thode est utile pour simuler selon une loi jointe, lorsqu'il est plus simple d'Ã©chantillonner de chaque variable conditionnellement Ã  toutes les autres plutÃ´t que directement de cette loi jointe. L'algorithme est donnÃ© par: \n",
    "\n",
    "\n",
    "1.   Tirage d'un vecteur de valeurs initiales pour toutes les variables $X_i$\n",
    "2.   Pour toutes les variable $X_i$ choisies dans un ordre alÃ©atoire, Ã©chantillonnage d'une nouvelle valeur: $X_i \\sim p(x_i\\mid x_1,\\dots,x_{i-1},x_{i+1},\\dots,x_n)$\n",
    "3.   Recommencer en 2 tant qu'on souhaite encore des Ã©chantillons\n",
    "\n",
    "Notons qu'il est souvent utile d'exploiter la relation suivante, qui indique que pour Ã©chantillonner de la loi conditionnelle, il suffit d'Ã©chantillonner chaque variable proportionnellement Ã  la loi jointe, avec toutes les autres variables fixÃ©es: \n",
    "$$p(x_j\\mid x_1,\\dots,x_{j-1},x_{j+1},\\dots,x_n) = \\frac{p(x_1,\\dots,x_n)}{p(x_1,\\dots,x_{j-1},x_{j+1},\\dots,x_n)} \\propto p(x_1,\\dots,x_n)$$\n",
    "\n",
    "AprÃ¨s une pÃ©riode dite de $burnin$ d'un nombre d'Ã©poques Ã  dÃ©finir, l'algorithme Ã©met des Ã©chantillons qui suivent la loi jointe connaissant les observations. Lorsque l'objectif est d'estimer des probabilitÃ©s marginales, on fait alors tourner cet algorithme pendant une certain nombre d'Ã©poques aprÃ¨s la pÃ©riode de $burnin$, au cours desquelles on recence les diffÃ©rentes affectations de chacune des variables Ã©tudiÃ©es. \n",
    "\n",
    "Pour mettre en oeuvre cet algorithme, nous aurons aurons besoin d'avoir accÃ¨s rapidement aux prÃ©decesseurs et successeurs dans le graphe. La mÃ©thode ci-dessous retourne un couple de dictionnaires Ã  partir du graphe: \n",
    " \n",
    "\n",
    "*   $preds[i]$  contient la liste des prÃ©dÃ©cesseurs du  noeud $i$, sous la forme d'une liste de triplets $(j,k_{j,i},r_{j,i})$ pour tous les $j$ prÃ©cÃ©dant $i$ dans le graphe.    \n",
    "*   $succs[i]$  contient la liste des successeurs du  noeud $i$, sous la forme d'une liste de triplets $(j,k_{i,j},r_{i,j})$ pour tous les $j$ pointÃ©s par $i$ dans le graphe.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0sPmzchnSP3r",
    "outputId": "66b3d635-6c9b-4bea-a6d7-4c9e2b60ff75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds= {1: [(0, 0.9, 0.2), (8, 0.8, 14)], 0: [(1, 0.9, 3)], 2: [(1, 0.2, 1), (3, 0.4, 0.5)], 3: [(2, 0.5, 0.2), (4, 0.9, 2), (1, 0.5, 2)], 4: [(2, 0.9, 10)], 5: [(2, 0.5, 0.5)], 7: [(5, 0.7, 15), (6, 0.1, 4)], 6: [(1, 0.2, 3)], 8: [(1, 0.8, 0.8)], 9: [(8, 0.2, 0.1), (10, 0.9, 1)], 10: [(1, 0.5, 12)]}\n",
      "succs= {0: [(1, 0.9, 0.2)], 1: [(0, 0.9, 3), (2, 0.2, 1), (3, 0.5, 2), (6, 0.2, 3), (8, 0.8, 0.8), (10, 0.5, 12)], 2: [(3, 0.5, 0.2), (4, 0.9, 10), (5, 0.5, 0.5)], 3: [(2, 0.4, 0.5)], 4: [(3, 0.9, 2)], 5: [(7, 0.7, 15)], 6: [(7, 0.1, 4)], 8: [(9, 0.2, 0.1), (1, 0.8, 14)], 10: [(9, 0.9, 1)]}\n"
     ]
    }
   ],
   "source": [
    "# prÃ©-calcul des prÃ©cÃ©cesseurs et successeurs pour gagner du temps ensuite\n",
    "def getPredsSuccs(graph):\n",
    "    names,gk,gr=graph\n",
    "    nbNodes=len(names)\n",
    "    preds={}\n",
    "    succs={}\n",
    "    for (a,b),v in gk.items():\n",
    "      s=succs.get(a,[])\n",
    "      s.append((b,v,gr[(a,b)]))\n",
    "      succs[a]=s\n",
    "      p=preds.get(b,[])\n",
    "      p.append((a,v,gr[(a,b)]))\n",
    "      preds[b]=p\n",
    "    return (preds,succs)\n",
    "preds,succs=getPredsSuccs(graph)\n",
    "print(\"preds=\",preds)\n",
    "print(\"succs=\",succs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vk-vCmVX6HtV"
   },
   "source": [
    "Pour calculer les probabilitÃ©s conditionnelles, il faut prendre en compte les quantitÃ©s suivantes: \n",
    "\n",
    "\n",
    "*   ProbabilitÃ© pour $j$ d'Ãªtre infectÃ© par $i$ au temps $t_j$ connaissant $t_i < t_j$:  \n",
    "$$\\alpha_{i,j}=k_{i,j}r_{i,j} exp(-r_{i,j}(t_j-t_i))$$\n",
    "*   ProbabilitÃ© pour $j$ de ne pas Ãªtre infectÃ© par $i$ jusqu'au temps $t$:\n",
    "$$\\beta_{i,j}=k_{i,j} exp(-r_{i,j}(t_j-t_i)) + 1 - k_{i,j}$$\n",
    "*   ProbabilitÃ© pour $j$ d'Ãªtre infectÃ© au temps $t_j$ connaissant les prÃ©decesseurs infectÃ©s avant $t_j$:\n",
    "$$h_{j}=\\prod_{i \\in preds[j], t_i<t_j} \\beta_{i,j} \\sum_{i \\in preds[i], t_i<t_j} \\alpha_{i,j} / \\beta_{i,j}$$\n",
    "*   ProbabilitÃ© pour $j$ de ne pas Ãªtre infectÃ© avant $maxT$ connsaissant ses prÃ©decesseurs infectÃ©s:\n",
    "$$g_{j}=\\prod_{i \\in preds[j], t_i<t_j} \\left(k_{i,j} exp(-r_{i,j}(maxT-t_i)) + 1 - k_{i,j}\\right)=\\prod_{i \\in preds[j], t_i<t_j} \\beta_{i,j}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Dans la mÃ©thode $computeab(v, times, preds)$, on prÃ©pare le calcul et les mises Ã  jour de ces quantitÃ©s. La mÃ©thode calcule, pour un noeud $v$ selon les temps d'infection courants donnÃ©s dans $times$, deux quantitÃ©s $a$ et $b$: \n",
    "\n",
    "$$a= \\left\\{\n",
    "\\begin{array}{l}\n",
    "\\max(1e^{-20}, \\sum_{i \\in preds[v], t_i<t_v} \\alpha_{i,v} / \\beta_{i,v}) \\mbox{ si: } t_v< maxT \\\\\n",
    "1 \\mbox{ sinon }\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$ \n",
    "\n",
    "$$b=\\sum_{i \\in preds[v], t_i<t_v} \\log \\beta_{i,v}$$\n",
    "\n",
    "Si $v$ appartient aux sources, on retourne $(a,b)=(1,0)$\n",
    "\n",
    "ComplÃ©ter la mÃ©thode $computeab$ donnÃ©e ci-dessous:   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cOnGCJCBSulp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0)\n",
      "(0.17610107365772137, -0.17810126145719926)\n",
      "(0.012293749653343879, -0.21077360840944234)\n",
      "(1.0, -1.1230118785518794)\n"
     ]
    }
   ],
   "source": [
    "eps=1e-20\n",
    "\n",
    "def computeab(v, times, preds, maxT, eps=1e-20):\n",
    "    preds=preds.get(v,[])\n",
    "    t=times[v]\n",
    "    if t==0:\n",
    "        return (1,0)\n",
    "    a=eps\n",
    "    b=0\n",
    "    if len(preds)>0:\n",
    "        c,k,r=map(np.array,zip(*preds))\n",
    "        somme_alpha_sur_beta=0\n",
    "        somme_log_beta=0\n",
    "        for j in range(len(preds)):\n",
    "            previous=preds[j][0]\n",
    "            k=preds[j][1]\n",
    "            r=preds[j][2]\n",
    "            tj=times[previous]\n",
    "            if tj<t:\n",
    "                alpha=k*r*np.exp(-r*(t-tj))\n",
    "                beta=k*np.exp(-r*(t-tj))+1-k\n",
    "                somme_alpha_sur_beta+=alpha/beta\n",
    "                somme_log_beta+=np.log(beta)\n",
    "        if t<maxT:\n",
    "            a=np.maximum(eps,somme_alpha_sur_beta)\n",
    "        else:\n",
    "            a=1.0\n",
    "        b=somme_log_beta\n",
    "    return (a,b)\n",
    "\n",
    "\n",
    "\n",
    "nbNodes=len(graph[0])\n",
    "times=np.array([maxT]*nbNodes,dtype=float)\n",
    "times[0]=0\n",
    "times[1]=1\n",
    "times[2]=4\n",
    "\n",
    "print(computeab(0,times,preds, maxT, eps))\n",
    "print(computeab(1,times,preds, maxT, eps))\n",
    "print(computeab(2,times,preds, maxT, eps))\n",
    "print(computeab(3,times,preds, maxT, eps))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujNcsUdcfKYR"
   },
   "source": [
    "VÃ©rification : \n",
    "\n",
    "\n",
    "```\n",
    "(1, 0)\n",
    "(0.17610107365772135, -0.17810126145719926)\n",
    "(0.012293749653343877, -0.2107736084094422)\n",
    "(1.0, -1.12301187855188)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXnKXCMfLMK-"
   },
   "source": [
    "La mÃ©thode $computell$ calcule la log-vraisemblance d'une diffusion (reprÃ©sentÃ©e par le tableau times), en appelant la mÃ©thode computeab sur l'ensemble des noeuds du rÃ©seau. Elle retourne un triplet (log-likelihood, sa, sb), avec $sa$ et $sb$ les tables des valeurs $a$ et $b$ pour tous les noeuds.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "aM0K-VhPUXJn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll= -13.117139892397578\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "like_indiv= [1.         0.14737154 0.00995741 0.32529856 0.1        0.52489353\n",
      " 0.8        1.         0.20059727 1.         0.5       ]\n"
     ]
    }
   ],
   "source": [
    "def computell(times,preds, maxT, eps):\n",
    "    ll=0.0\n",
    "    sa=np.zeros((len(times)))\n",
    "    sb=np.zeros((len(times)))\n",
    "    for i in range(len(times)):\n",
    "        a,b=computeab(i,times,preds,maxT)\n",
    "        sa[i]=a\n",
    "        sb[i]=b\n",
    "        ll+=np.log(a)+b\n",
    "    return ll,sa,sb\n",
    "\n",
    "ll,sa,sb=computell(times,preds, maxT, eps)\n",
    "print(\"ll=\",ll)\n",
    "print(times)\n",
    "print(\"like_indiv=\",np.exp(np.log(sa)+sb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akb4kVy3hK2X"
   },
   "source": [
    "VÃ©rification : \n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "ll= -13.117139892397578\n",
    "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
    "like_indiv= [1.         0.14737154 0.00995741 0.32529856 0.1        0.52489353\n",
    " 0.8        1.         0.20059727 1.         0.5       ]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNlDzJeFNb60"
   },
   "source": [
    "Afin de prÃ©parer les mises Ã  jour lors des affectations successives des variables du Gibbs Sampling, on propose de dÃ©finir une mÃ©thode $removeV(v,times,succs,sa,sb)$ qui retire temporairement du rÃ©seau un noeud $v$, en passant son temps d'infection Ã  -1 dans times et en retirant sa contribution aux valeurs a et b (contenues dans sa et sb) de tous ses successeurs $j$ tels que $t_j > t_v$ (y compris donc les non infectÃ©s qui sont Ã  $t_j=maxT$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEGzpS_DaRX5",
    "outputId": "f1cd5174-87e0-426e-f665-f4a1b2ed89f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sa= [1.         0.17610107 0.01229375 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.        ]\n",
      "sb= [ 0.         -0.17810126 -0.21077361 -1.12301188 -2.30258509 -0.64455983\n",
      " -0.22314355  0.         -1.60645602  0.         -0.69314718]\n",
      "diffa= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "diffb= [0.         0.         0.         1.12301188 0.         0.\n",
      " 0.         0.         0.         0.         0.        ]\n",
      "diffa= [ 0.          0.82389893 -0.01229375  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.        ]\n",
      "diffb= [0.         0.17810126 0.21077361 0.69314717 0.         0.\n",
      " 0.22314355 0.         1.60645602 0.         0.69314718]\n"
     ]
    }
   ],
   "source": [
    "def removeV(v,times,succs,sa,sb):\n",
    "  succs=succs.get(v,[])\n",
    "  t=times[v]\n",
    "  if t<0:\n",
    "    return \n",
    "  times[v]=-1\n",
    "  sa[v]=1.0\n",
    "  sb[v]=0.0\n",
    "  if len(succs)>0:\n",
    "    c,k,r=map(np.array,zip(*succs))\n",
    "    tp=times[c]\n",
    "    which=(tp>t)\n",
    "\n",
    "    tp=tp[which]\n",
    "    dt=tp-t\n",
    "    k=k[which]\n",
    "    r=r[which]\n",
    "    c=c[which]\n",
    "    rt = -r*dt\n",
    "    b1=k*np.exp(rt)\n",
    "    b=b1+1.0-k\n",
    "    \n",
    "    a=r*b1\n",
    "    a=a/b\n",
    "    b=np.log(b)\n",
    "    \n",
    "    sa[c]=sa[c]-np.where(tp<maxT,a,0.0)\n",
    "    sa[c]=np.where(sa[c]>eps,sa[c],eps)\n",
    "    sb[c]=sb[c]-b\n",
    "    sb[c]=np.where(sb[c]>0,0,sb[c])\n",
    "\n",
    "\n",
    "#Test\n",
    "print(\"sa=\",sa)\n",
    "print(\"sb=\",sb)\n",
    "\n",
    "nsa=np.copy(sa)\n",
    "nsb=np.copy(sb)\n",
    "ntimes=np.copy(times)\n",
    "removeV(3,ntimes,succs,nsa,nsb)\n",
    "print(\"diffa=\",nsa-sa)\n",
    "print(\"diffb=\",nsb-sb)\n",
    "\n",
    "nsa=np.copy(sa)\n",
    "nsb=np.copy(sb)\n",
    "ntimes=np.copy(times)\n",
    "removeV(1,ntimes,succs,nsa,nsb)\n",
    "print(\"diffa=\",nsa-sa)\n",
    "print(\"diffb=\",nsb-sb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb8iIMwgO6D9"
   },
   "source": [
    "La mÃ©thode addVatT fait l'inverse: elle rajoute un noeud qui Ã©tait retirÃ© du rÃ©seau, avec un temps $newt$. Il faut alors mettre Ã  jour les valeurs a et b (dans sa et sb) de tous les successeurs de $v$ tels que $t_j > newt$ et calculer les valeurs a et b du noeud v. \n",
    "\n",
    "ComplÃ©ter le code ci-dessous: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "9sDiLiXnngog"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.830251606174211e-05 8.555487921315824e-05 3.830251606174211e-05 -13.117139892397578\n",
      "0.14737153555403676 1.0000000000169125e-21 0.14737153555403676 -13.117139892397578\n",
      "0.524893534183932 2.999999999999998e-21 0.524893534183932 -13.117139892397578\n"
     ]
    }
   ],
   "source": [
    "def addVatT(v,times,newt,preds,succs,sa,sb):\n",
    "    t=times[v]\n",
    "    if t>=0:\n",
    "        raise Error(\"v  must have been removed before\")\n",
    "  \n",
    "  #>>>>>>>>>>>>\n",
    "  # votre code ici\n",
    "  #<<<<<<<<<<<<<<<<<<<\n",
    "    times[v]=newt\n",
    "    sa[v],sb[v]=computeab(v,times,preds,maxT) #a et b pour le noeud supprime\n",
    "    for i in preds:  \n",
    "        sa[i],sb[i]=computeab(i,times,preds,maxT)#mise a jour des valeurs\n",
    "# Tests: \n",
    "   \n",
    "nsa=np.copy(sa)\n",
    "nsb=np.copy(sb)\n",
    "c,_,_=map(np.array,zip(*succs[1]))\n",
    "c=np.append(c,1)\n",
    "ll=np.sum((np.log(nsa)+nsb)[c])           # somme des logvraisemblances pouvant être modifiées par la modification du temps de 1 (avant modif)\n",
    "removeV(1,times,succs,nsa,nsb)\n",
    "addVatT(1,times,2,preds,succs,nsa,nsb)\n",
    "ll2=np.sum((np.log(nsa)+nsb)[c])          # somme des logvraisemblances pouvant avoir été modifiées par la modification du temps de 1 (après modif)\n",
    "removeV(1,times,succs,nsa,nsb)\n",
    "addVatT(1,times,1,preds,succs,nsa,nsb)\n",
    "ll3=np.sum((np.log(nsa)+nsb)[c])          # somme des logvraisemblances pouvant  avoir été modifiées par la modification du temps de 1 (après remise dans l'état initial)\n",
    "llall=np.sum(np.log(nsa)+nsb)             # logvraisemblance globale\n",
    "print(np.exp(ll),np.exp(ll2),np.exp(ll3),llall)\n",
    "\n",
    "c,_,_=map(np.array,zip(*succs[0]))\n",
    "c=np.append(c,0)\n",
    "ll=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(0,times,succs,nsa,nsb)\n",
    "addVatT(0,times,maxT,preds,succs,nsa,nsb)\n",
    "ll2=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(0,times,succs,nsa,nsb)\n",
    "addVatT(0,times,0,preds,succs,nsa,nsb)\n",
    "ll3=np.sum((np.log(nsa)+nsb)[c])\n",
    "llall=np.sum(np.log(nsa)+nsb)\n",
    "print(np.exp(ll),np.exp(ll2),np.exp(ll3),llall)\n",
    "\n",
    "c,_,_=map(np.array,zip(*succs[5]))\n",
    "c=np.append(c,5)\n",
    "ll=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(5,times,succs,nsa,nsb)\n",
    "addVatT(5,times,1,preds,succs,nsa,nsb)\n",
    "ll2=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(5,times,succs,nsa,nsb)\n",
    "addVatT(5,times,maxT,preds,succs,nsa,nsb)\n",
    "ll3=np.sum((np.log(nsa)+nsb)[c])\n",
    "llall=np.sum(np.log(nsa)+nsb)\n",
    "print(np.exp(ll),np.exp(ll2),np.exp(ll3),llall)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBg9T8k2hhmO"
   },
   "source": [
    "VÃ©rification : \n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "3.830251606174211e-05 8.555487921315824e-05 3.830251606174211e-05 -13.117139892397578\n",
    "0.14737153555403676 1.0000000000169125e-21 0.14737153555403676 -13.117139892397578\n",
    "0.5248935341839319 2.999999999999998e-21 0.5248935341839319 -13.117139892397578\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3isBRUNi3JPA"
   },
   "source": [
    "Pour Ã©chantillonner pour une variable $i$, il faudra Ãªtre Ã  mÃªme de comparer les vraisemblances selon les diffÃ©rentes affectations. Cela implique de calculer la somme de toutes ces vraisemblances. Mais pour rÃ©aliser cette somme, il faudrait que nous sortions de la reprÃ©sentation logarithmique: $\\sum_{t_i} exp(log(p(t_1,\\dots,t_i,\\dots,t_n))$. Si on le fait de cette maniÃ¨re, on risque d'avoir des arrondis Ã  0 presque partout. Une possibilitÃ© (log-sum-exp trick) est d'exploiter la relation suivante:  \n",
    "\n",
    "$$\\log\\sum_i x_i = x^* + \\log\\left( \\exp(x_1-x^*)+ \\cdots + \\exp(x_n-x^*) \\right)$$\n",
    "avec $x^* = \\max{\\{x_1, \\dots, x_n\\}}$\n",
    "\n",
    "ComplÃ©ter la mÃ©thode logsumexp suivante, qui rÃ©alise cette somme en Ã©vitant les problÃ¨mes numÃ©riques: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZuOJI7B3p0O",
    "outputId": "dd48b42f-6b96-4121-9a1c-291e8468288f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.54045945 -0.67334455] [-3.54045945 -0.67334455]\n"
     ]
    }
   ],
   "source": [
    "def logsumexp(x,axis=-1):\n",
    "  #>>>>>>>>>>\n",
    "  # votre code ici\n",
    "  #<<<<<<<<<<\n",
    "    xe=np.amax(x)\n",
    "    return xe+np.log(np.sum(np.exp(x-xe),axis))\n",
    " \n",
    "  \n",
    "\n",
    "#Test: \n",
    "x=np.array([[0.001,0.02,0.008],[0.1,0.01,0.4]])\n",
    "r=np.log(np.sum(x,-1))\n",
    "x=np.log(x)\n",
    "r2=logsumexp(x)\n",
    "print(r2,r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZpzgRBZhtOm"
   },
   "source": [
    "VÃ©rification : \n",
    "\n",
    "\n",
    "```\n",
    "[-3.54045945 -0.67334455] [-3.54045945 -0.67334455]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqVI0e9T85x-"
   },
   "source": [
    "On souhaite maintenant mettre en place une mÃ©thode $sampleV(v,times,newt,preds,succs,sa,sb,k,k2)$ qui sample un nouveau temps d'infection pour le noeud $v$, connaissant les temps de tous les autres noeuds dans $times$ (ainsi que leurs valeurs $a$ et $b$ correspondantes contenues dans sa et sb). Puisque le domaine de support de $t_v$ est continu, on doit faire quelques approximations en se basant sur une discrÃ©tisation des valeurs possibles:\n",
    "\n",
    "1.   On dÃ©coupe la plage de temps $[0;maxT]$ en $k$ bins rÃ©guliers. Dans chaque bin $i$, on Ã©chantillonne uniformÃ©ment un temps, pour obtenir $k$ points $d_1,\\dots,d_k$. Si $t_v < maxT$, on ajoute $t_v$ Ã  cet ensemble de points pour gagner en stabilitÃ© (insÃ©rÃ© dans la liste de maniÃ¨re Ã  conserver l'ordre croissant). \n",
    "2.   On considÃ¨re chaque point $d_i$ comme le prototype d'un bin $[(d_i+d_{i-1})/2,(d_i+d_{i+1})/2]$. Pour $d_1$ on prend $[0,(d_1+d_2)/2]$ et pour $d_k$ on prend   $[(d_k+d_{k-1})/2,maxT]$. On fait l'hypothÃ¨se que la densitÃ© de probabilitÃ© est constante sur l'ensemble de chaque bin $i$, que l'on Ã©value en  $t_v=d_i$.   La probabilitÃ© que l'on Ã©chantillonne dans le bin $i$ est alors Ã©gale Ã : $p(t_v \\in bin_i | \\{t_u\\}_{ u \\in V\\setminus v}) =  \\frac{z_i \\times l_i}{\\sum_j z_j \\times l_j + z_{maxT}}$, avec $z_i$ la vraisemblance  calculÃ©e selon $t_v =d_i$, $l_i$ la taille du bin $i$ et $z_{maxT}$ la vraisemblance  calculÃ©e pour $t_v=maxT$. La probabilitÃ© que $v$ ne soit pas infectÃ© dans la diffusion est alors donnÃ©e par : $p(t_v = maxT | \\{t_u\\}_{ u \\in V\\setminus v}) =  \\frac{z_{maxT}}{\\sum_j z_j \\times l_j + z_{maxT}}$.\n",
    "3. On Ã©chantillonne une variable $x$ proportionnellement aux probabilitÃ©s calculÃ©es Ã  l'Ã©tape prÃ©cÃ©dente.  Si $x$ ne correspond pas Ã  $maxT$, $v$ est alors infectÃ© Ã  un temps inclus dans l'intervale du bin correspondant Ã  $x$. Il s'agit alors de re-Ã©chantillonner $k2$ points uniformÃ©ment dans ce bin et de calculer les densitÃ©s en ces points (pour gagner en stabilitÃ© on ajoute le prototype du bin $d_i$). Le nouveau temps de $v$ est alors Ã©chantillonnÃ© proportionnellement Ã  ces densitÃ©s.\n",
    "\n",
    "Le code de la mÃ©thode de sampling est donnÃ© ci-dessous:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "K3QmBCRbhkLM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.          1.          4.         10.         10.          4.20931617\n",
      " 10.         10.         10.         10.         10.        ]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "\n",
    "def getLL(v,times,nt,preds,succs,sa,sb,onUsers=None):\n",
    "  sa=np.copy(sa)\n",
    "  sb=np.copy(sb)\n",
    "  if onUsers is None:\n",
    "    onUsers=range(len(times))\n",
    "  addVatT(v,times,nt,preds,succs,sa,sb)\n",
    "  times[v]=-1\n",
    "  ll=np.sum((np.log(sa)+sb)[onUsers])\n",
    "  return (ll,sa,sb)\n",
    "\n",
    "  \n",
    "def sampleV(v,times,preds,succs,sa,sb,k,k2):\n",
    "  \n",
    "  nbCandidateT=k\n",
    "  bounds=np.linspace(0,maxT,nbCandidateT)\n",
    "  newt=np.random.uniform(bounds[:-1],bounds[1:])\n",
    "  \n",
    "  if times[v]<maxT:\n",
    "    idx = newt.searchsorted(times[v])\n",
    "    newt=np.concatenate((newt[:idx], [times[v]], newt[idx:]),axis=0)\n",
    "    nbCandidateT+=1\n",
    "  newt=np.append(newt,[maxT])\n",
    "  \n",
    "  if v in succs:\n",
    "    c,_,_=map(list,zip(*succs.get(v,[])))\n",
    "  else:\n",
    "    c=[]\n",
    "  c.append(v)\n",
    "  c=np.array(c)\n",
    "  oldll=np.sum((np.log(sa)+sb)[c])\n",
    "  otime=times[v]\n",
    "  nsa=np.copy(sa)\n",
    "  nsb=np.copy(sb)\n",
    "  removeV(v,times,succs,nsa,nsb)\n",
    "  lls=[getLL(v,times,nt,preds,succs,nsa,nsb,onUsers=c) for nt in newt]\n",
    "  ll,la,lb=zip(*lls)\n",
    "  ll=list(ll)\n",
    "  ll=np.array(ll)\n",
    "  \n",
    "  diffsx=(newt[1:]-newt[:-1])/2.0\n",
    "  diffsx[1:]=diffsx[1:]+diffsx[:-1]\n",
    "  diffsx[0]+=newt[0]\n",
    "  diffsx[-1]+=(maxT-newt[nbCandidateT-1])/2.0\n",
    "  areas=np.log(diffsx)+ll[:-1]\n",
    "  lln=np.append(areas,ll[-1])\n",
    "  \n",
    "\n",
    "  p=np.exp(lln-logsumexp(lln))\n",
    "  \n",
    "  \n",
    "  i=np.random.choice(range(len(p)),1,p=p).sum()\n",
    "  if i==(len(p)-1):\n",
    "    times[v]=maxT\n",
    "    np.copyto(sa,np.array(la[-1]))\n",
    "    np.copyto(sb,np.array(lb[-1]))\n",
    "  else: \n",
    "      if i>0: \n",
    "        bi=(newt[i]+newt[i-1])/2.0\n",
    "      else:\n",
    "        bi=0\n",
    "      if i<(len(p)-2): \n",
    "        bs=(newt[i]+newt[i+1])/2.0\n",
    "      else:\n",
    "        bs=maxT\n",
    "      bounds=np.linspace(bi,bs,k2)\n",
    "      newt=np.concatenate(([newt[i]],np.random.uniform(bounds[:-1],bounds[1:])))\n",
    "      lls=[getLL(v,times,nt,preds,succs,nsa,nsb,onUsers=c) for nt in newt]\n",
    "      ll,la,lb=zip(*lls)\n",
    "      ll=np.array(ll)\n",
    "      p=np.exp(ll-logsumexp(ll))\n",
    "      \n",
    "      i=np.random.choice(range(len(p)),1,p=p).sum()\n",
    "      \n",
    "      times[v]=newt[i]\n",
    "      np.copyto(sa,np.array(la[i]))\n",
    "      np.copyto(sb,np.array(lb[i]))\n",
    "   \n",
    "  \n",
    "times=np.array([maxT]*nbNodes,dtype=float)\n",
    "times[0]=0\n",
    "times[1]=1\n",
    "times[2]=4\n",
    "np.random.seed(0)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,10,10)\n",
    "print(times)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0RMM_c2siHez"
   },
   "source": [
    "VÃ©rification : \n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
    "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
    "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
    "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
    "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
    "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
    "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
    "[ 0.          1.          4.         10.         10.          4.20931617\n",
    " 10.         10.         10.         10.         10.        ]\n",
    "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCdSA3NF8CrE"
   },
   "source": [
    "ComplÃ©ter la mÃ©thode de Gibbs Sampling $gb$ ci-dessous, avec $k$ le nombre de bins Ã  utiliser et $k2$ le nombre de points Ã  Ã©chantillonner dans le bin choisi. Le paramÃ¨tre $ref$ correspond Ã  un vecteur de probabilitÃ©s marginales de rÃ©fÃ©rence (par exemple obtenu par MonteCarlo lorsque c'est possible) avec lequel on peut afficher la distance MSE au fur et Ã  mesure du processus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xsnQHVcdjfVT",
    "outputId": "8c274aa7-e425-4ed7-d3a6-a114a85988b8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-acf4ad9b4461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# On teste ici avec seulement des sources (i.e., des infectÃ©s au temps 0), car cela permet de comparer Ã  la ref MonteCarlo (mais il faudrait aussi tester avec d'autres infectÃ©s : c'est l'objectif).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetProbaMC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mburnin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-acf4ad9b4461>\u001b[0m in \u001b[0;36mgb\u001b[0;34m(graph, infections, burnin, nbEpochs, k, k2, ref)\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0;31m# votre code ici\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0;31m#>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# On teste ici avec seulement des sources (i.e., des infectÃ©s au temps 0), car cela permet de comparer Ã  la ref MonteCarlo (mais il faudrait aussi tester avec d'autres infectÃ©s : c'est l'objectif).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rate' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(1)\n",
    "def gb(graph,infections,burnin=1000,nbEpochs=10000,k=100,k2=50, ref=None):\n",
    "   #>>>>>>>>>>>>>>>>>>>>>>>\n",
    "   # votre code ici\n",
    "   #>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "   return rate\n",
    "\n",
    "# On teste ici avec seulement des sources (i.e., des infectÃ©s au temps 0), car cela permet de comparer Ã  la ref MonteCarlo (mais il faudrait aussi tester avec d'autres infectÃ©s : c'est l'objectif). \n",
    "ref=getProbaMC(graph,[0],maxT) \n",
    "rate=gb(graph,[(0,0)],burnin=100,ref=ref)\n",
    "print(rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iqx6CQ4vQ8rr"
   },
   "source": [
    "# Partie optionnelle\n",
    "\n",
    "L'algorithme de Metropolis-Hasting est une autre mÃ©thode de type MCMC qui utilise une distribution d'Ã©chantillonnage pour se dÃ©placer dans l'espace des points considÃ©rÃ©s. Il s'agit de dÃ©finir une distribution $q(y_{t+1}|x_t)$ de laquelle on sait gÃ©nÃ©rer un dÃ©placement. L'algorithme procÃ©de alors de la maniÃ¨re suivante: \n",
    "\n",
    "\n",
    "1.   GÃ©nÃ©rer $y_{t+1}$ selon $q(y_{t+1}|x_t)$ \n",
    "2.   Calculer la probabilitÃ© dâ€™acceptation $\\alpha(x_t,y_{t+1})=\\min\\left\\{\\frac{\\pi(y_{t+1})q(x_t|y_{t+1})}{\\pi(x_t)q(y_{t+1}|x_t)},1\\right\\} \\,\\!, \\text{ avec } \\pi(x_t) \\text{ la densitÃ© de probabilitÃ© de } x_t$\n",
    "3.   Prendre $x_{t+1}=\\begin{cases} y_{t+1}, & \\text{avec probabilitÃ©}\\,\\,\\alpha \\\\ x_t, & \\text{avec probabilitÃ©}\\,\\,1-\\alpha \\end{cases}$\n",
    "\n",
    "\n",
    "\n",
    "Dans notre cas, on propose de travailler avec des dÃ©placements correspondants Ã  des permutations d'un temps d'infection Ã  chaque itÃ©ration, comme dans le cadre du Gibbs Sampling. A chaque Ã©tape on choisit donc une variable Ã  modifier, on choisit un nouveau temps pour cette variable et on calcule la densitÃ© correspondante. La probabilitÃ© d'acceptation est ensuite calculÃ©e selon cette densitÃ© et la probabilitÃ© du dÃ©placement selon la distribution $q$ qui a servi Ã  gÃ©nÃ©rer le nouveau temps d'infection. On se propose de choisir $maxT$ avec une probabilitÃ© de 0.1. La probabilitÃ© $q(t_v|t)$ pour $t< maxT$ est alors Ã©gale  Ã   $0.9\\times \\frac{1}{maxT}$.\n",
    "\n",
    "ImplÃ©menter l'approche d'Ã©chantillonnage par Metropolis-Hasting pour notre problÃ¨me d'estimation de probabilitÃ©s marginales d'infection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TGoHITZmGxg-",
    "outputId": "e463281e-3ce0-4bba-c8b3-c2b44fbf8f7c"
   },
   "outputs": [],
   "source": [
    "# votre code ici\n",
    "\n",
    "ref=getProbaMC(graph,[0]) \n",
    "rate=mh(graph,[(0,0)],burnin=100,ref=ref)\n",
    "print(rate)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tme8_mapsi_2020_enonce",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
